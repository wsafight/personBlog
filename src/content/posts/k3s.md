---
title: K3s å®Œå…¨æŒ‡å—ï¼šè½»é‡çº§ Kubernetes ä»å…¥é—¨åˆ°å®æˆ˜
published: 2026-02-09
description: å…¨é¢ä»‹ç» K3s è½»é‡çº§ Kubernetes å‘è¡Œç‰ˆï¼Œæ¶µç›–æ¶æ„åŸç†ã€å®‰è£…é…ç½®ã€é›†ç¾¤ç®¡ç†ã€å­˜å‚¨ç½‘ç»œã€ç›‘æ§å‘Šè­¦ç­‰æ ¸å¿ƒå†…å®¹ã€‚K3s ä¸“ä¸ºè¾¹ç¼˜è®¡ç®—ã€IoT è®¾å¤‡å’Œèµ„æºå—é™ç¯å¢ƒè®¾è®¡ï¼Œæä¾›å®Œæ•´çš„ç”Ÿäº§çº§ Kubernetes ä½“éªŒã€‚
tags: [K3s, Kubernetes, å®¹å™¨ç¼–æ’, è¾¹ç¼˜è®¡ç®—, IoT, DevOps, äº‘åŸç”Ÿ]
category: DevOps
draft: false
---

K3s æ˜¯ç”± Rancher Labsï¼ˆç°ä¸º SUSE æ——ä¸‹ï¼‰å¼€å‘çš„è½»é‡çº§ Kubernetes å‘è¡Œç‰ˆï¼Œä¸“ä¸ºè¾¹ç¼˜è®¡ç®—ã€IoT è®¾å¤‡ã€CI/CD ç¯å¢ƒå’Œèµ„æºå—é™åœºæ™¯è®¾è®¡ã€‚

### å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

```bash
# å®‰è£…ä¸å¸è½½
curl -sfL https://get.k3s.io | sh -                    # å®‰è£… K3s
/usr/local/bin/k3s-uninstall.sh                         # å¸è½½ K3s

# é›†ç¾¤ç®¡ç†
sudo k3s kubectl get nodes                              # æŸ¥çœ‹èŠ‚ç‚¹
sudo systemctl status k3s                               # æŸ¥çœ‹æœåŠ¡çŠ¶æ€
sudo journalctl -u k3s -f                               # æŸ¥çœ‹æ—¥å¿—
sudo cat /var/lib/rancher/k3s/server/node-token        # è·å– token

# èµ„æºæ“ä½œ
kubectl get pods -A                                     # æŸ¥çœ‹æ‰€æœ‰ Pod
kubectl get svc,deploy,sts -n <namespace>              # æŸ¥çœ‹å¤šç§èµ„æº
kubectl describe pod <pod-name> -n <namespace>         # æŸ¥çœ‹è¯¦æƒ…
kubectl logs -f <pod-name> -n <namespace>              # æŸ¥çœ‹æ—¥å¿—
kubectl exec -it <pod-name> -- /bin/sh                 # è¿›å…¥å®¹å™¨

# è°ƒè¯•è¯Šæ–­
kubectl top nodes                                       # èµ„æºä½¿ç”¨
kubectl get events -n <namespace> --sort-by='.lastTimestamp'  # äº‹ä»¶
kubectl debug node/<node-name> -it --image=ubuntu      # èŠ‚ç‚¹è°ƒè¯•
kubectl run debug --image=busybox --rm -it -- sh       # ä¸´æ—¶ Pod

# å¤‡ä»½æ¢å¤
sudo k3s etcd-snapshot save --name backup-$(date +%F)  # åˆ›å»ºå¿«ç…§
sudo k3s etcd-snapshot ls                              # åˆ—å‡ºå¿«ç…§
```

### é‡è¦è·¯å¾„

```bash
/usr/local/bin/k3s              # K3s äºŒè¿›åˆ¶
/etc/rancher/k3s/               # é…ç½®æ–‡ä»¶ç›®å½•
  â”œâ”€â”€ config.yaml               # ä¸»é…ç½®æ–‡ä»¶
  â”œâ”€â”€ k3s.yaml                  # kubeconfig
  â””â”€â”€ registries.yaml           # é•œåƒä»“åº“é…ç½®
/var/lib/rancher/k3s/           # æ•°æ®ç›®å½•
  â”œâ”€â”€ server/db/                # SQLite æ•°æ®åº“
  â”œâ”€â”€ server/manifests/         # è‡ªåŠ¨éƒ¨ç½²æ¸…å•
  â””â”€â”€ server/tls/               # TLS è¯ä¹¦
/etc/systemd/system/k3s.service # systemd æœåŠ¡æ–‡ä»¶
```

### ç«¯å£åˆ—è¡¨

```
6443    - Kubernetes API Server
10250   - Kubelet API
8472    - Flannel VXLAN
51820   - Flannel Wireguard (å¯é€‰)
2379    - etcd (å¤šä¸»æ¨¡å¼)
2380    - etcd peer (å¤šä¸»æ¨¡å¼)
```

---

## 1. K3s ç®€ä»‹

### 1.1 ä»€ä¹ˆæ˜¯ K3s

**æ ¸å¿ƒç‰¹ç‚¹ï¼š**
- **è½»é‡çº§**ï¼šäºŒè¿›åˆ¶æ–‡ä»¶ä¸åˆ° 100MBï¼Œå†…å­˜å ç”¨çº¦ 512MB
- **ç®€å•**ï¼šå•ä¸€äºŒè¿›åˆ¶æ–‡ä»¶åŒ…å«æ‰€æœ‰ä¾èµ–
- **å®‰å…¨**ï¼šé»˜è®¤å¯ç”¨ TLSï¼Œæ”¯æŒ SELinux
- **ç”Ÿäº§å°±ç»ª**ï¼šå®Œå…¨ç¬¦åˆ CNCF Kubernetes è®¤è¯

### 1.2 é€‚ç”¨åœºæ™¯

```
âœ… è¾¹ç¼˜è®¡ç®—èŠ‚ç‚¹
âœ… IoT è®¾å¤‡ç®¡ç†
âœ… CI/CD æµæ°´çº¿
âœ… å¼€å‘æµ‹è¯•ç¯å¢ƒ
âœ… ARM æ¶æ„è®¾å¤‡ï¼ˆæ ‘è“æ´¾ç­‰ï¼‰
âœ… èµ„æºå—é™ç¯å¢ƒ
âœ… å•æœº Kubernetes å­¦ä¹ 
```

---

## 2. K3s æ¶æ„ä¸åŸç†

### 2.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        K3s Server                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  API Server  â”‚  â”‚  Scheduler   â”‚  â”‚  Controller  â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚   Manager    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Embedded Storage (SQLite/etcd)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Kubelet    â”‚  â”‚  Kube-proxy  â”‚  â”‚  Containerd  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ (Tunnel)
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        K3s Agent                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Kubelet    â”‚  â”‚  Kube-proxy  â”‚  â”‚  Containerd  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒç»„ä»¶è¯¦è§£

#### 2.2.1 å•ä¸€è¿›ç¨‹æ¶æ„

ä¼ ç»Ÿ Kubernetesï¼š
```bash
# éœ€è¦å¤šä¸ªç‹¬ç«‹è¿›ç¨‹
kube-apiserver
kube-controller-manager
kube-scheduler
kubelet
kube-proxy
etcd
```

K3s ä¼˜åŒ–ï¼š
```bash
# æ‰€æœ‰ç»„ä»¶æ‰“åŒ…åœ¨ä¸€ä¸ªäºŒè¿›åˆ¶æ–‡ä»¶ä¸­
k3s server  # åŒ…å« API Server + Controller + Scheduler + å­˜å‚¨
k3s agent   # åŒ…å« Kubelet + Kube-proxy
```

#### 2.2.2 åµŒå…¥å¼æ•°æ®åº“

**SQLite (é»˜è®¤)**
- å•èŠ‚ç‚¹éƒ¨ç½²
- é›¶é…ç½®ï¼Œè‡ªåŠ¨åˆå§‹åŒ–
- æ•°æ®å­˜å‚¨åœ¨ `/var/lib/rancher/k3s/server/db/state.db`

**etcd (å¯é€‰)**
- å¤šä¸»é«˜å¯ç”¨
- å†…åµŒæˆ–å¤–éƒ¨ etcd é›†ç¾¤
- é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒ

**å¤–éƒ¨æ•°æ®åº“ (å¯é€‰)**
- PostgreSQL
- MySQL
- é€‚ç”¨äºäº‘ç¯å¢ƒ

#### 2.2.3 å®¹å™¨è¿è¡Œæ—¶

K3s é»˜è®¤ä½¿ç”¨ **containerd**ï¼š
```
ä¼˜åŠ¿ï¼š
- è½»é‡çº§ï¼Œä½å†…å­˜å ç”¨
- CRI åŸç”Ÿæ”¯æŒ
- ç§»é™¤ Docker ä¾èµ–
- æ›´å¿«çš„é•œåƒæ‹‰å–
```

#### 2.2.4 ç½‘ç»œç»„ä»¶

**Flannel (é»˜è®¤ CNI)**
```yaml
é»˜è®¤é…ç½®ï¼š
- Backend: VXLAN
- Network: 10.42.0.0/16
- ç®€å•å¯é ï¼Œå¼€ç®±å³ç”¨
```

**Traefik (é»˜è®¤ Ingress)**
```yaml
ç‰¹ç‚¹ï¼š
- è‡ªåŠ¨æœåŠ¡å‘ç°
- æ”¯æŒ Let's Encrypt
- Dashboard ç›‘æ§
```

### 2.3 ç²¾ç®€åŸç†

K3s é€šè¿‡ä»¥ä¸‹æ–¹å¼å‡å°‘ä½“ç§¯å’Œèµ„æºå ç”¨ï¼š

#### ç§»é™¤ç»„ä»¶
```
âŒ Cloud Providerï¼ˆäº‘å‚å•†ç‰¹å®šï¼‰
âŒ å­˜å‚¨æ’ä»¶ï¼ˆåªä¿ç•™å¿…è¦çš„ï¼‰
âŒ Legacy API
âŒ éå…³é”® Admission Controllers
```

#### æ›¿æ¢ç»„ä»¶
```
Docker â†’ Containerd
etcd â†’ SQLite (å¯é€‰)
iptables â†’ nftables (å¯é€‰)
```

#### æ‰“åŒ…ç­–ç•¥
```go
// ä¼ªä»£ç å±•ç¤ºæ‰“åŒ…é€»è¾‘
func BuildK3s() {
    components := []Component{
        APIServer,
        ControllerManager,
        Scheduler,
        Kubelet,
        KubeProxy,
        Containerd,
        Flannel,
        Traefik,
    }

    // ç¼–è¯‘ä¸ºå•ä¸€é™æ€äºŒè¿›åˆ¶
    binary := CompileStatic(components)

    // å‹ç¼©ä¼˜åŒ–
    optimized := Compress(binary, UPX)

    return optimized // ~70MB
}
```

---

## 3. K3s vs K8s å¯¹æ¯”

| ç‰¹æ€§ | K3s | K8s |
|------|-----|-----|
| **äºŒè¿›åˆ¶å¤§å°** | ~70MB | ~1.5GB+ |
| **å†…å­˜å ç”¨** | ~512MB | ~2GB+ |
| **å®‰è£…æ—¶é—´** | < 1 åˆ†é’Ÿ | 10-30 åˆ†é’Ÿ |
| **ä¾èµ–** | æ— ï¼ˆå•ä¸€äºŒè¿›åˆ¶ï¼‰ | Docker/containerd + å¤šä¸ªç»„ä»¶ |
| **é»˜è®¤å­˜å‚¨** | SQLite | etcd |
| **CNI** | Flannel | éœ€æ‰‹åŠ¨å®‰è£… |
| **Ingress** | Traefik | éœ€æ‰‹åŠ¨å®‰è£… |
| **è¯ä¹¦ç®¡ç†** | è‡ªåŠ¨ | æ‰‹åŠ¨/kubeadm |
| **é€‚ç”¨åœºæ™¯** | è¾¹ç¼˜/å•æœº/IoT | å¤§è§„æ¨¡é›†ç¾¤ |

---

## 4. å¿«é€Ÿå¼€å§‹

### 4.1 å•èŠ‚ç‚¹å®‰è£…

```bash
# å®‰è£… K3s Server
curl -sfL https://get.k3s.io | sh -

# æ£€æŸ¥çŠ¶æ€
sudo systemctl status k3s

# æŸ¥çœ‹èŠ‚ç‚¹
sudo k3s kubectl get nodes

# è®¾ç½® kubectl åˆ«å
echo "alias kubectl='sudo k3s kubectl'" >> ~/.bashrc
source ~/.bashrc
```

**å®‰è£…è¿‡ç¨‹è¯¦è§£ï¼š**
```bash
# 1. ä¸‹è½½ k3s äºŒè¿›åˆ¶åˆ° /usr/local/bin/k3s
# 2. åˆ›å»º systemd æœåŠ¡ /etc/systemd/system/k3s.service
# 3. ç”Ÿæˆ kubeconfig åˆ° /etc/rancher/k3s/k3s.yaml
# 4. å¯åŠ¨æœåŠ¡å¹¶è®¾ç½®å¼€æœºè‡ªå¯
# 5. ç­‰å¾…æ‰€æœ‰ç³»ç»Ÿ Pod è¿è¡Œ
```

### 4.2 é«˜å¯ç”¨å¤šä¸»å®‰è£…

```bash
# ç¬¬ä¸€ä¸ªä¸»èŠ‚ç‚¹ï¼ˆåˆå§‹åŒ– etcdï¼‰
curl -sfL https://get.k3s.io | sh -s - server \
  --cluster-init \
  --tls-san=k3s-lb.example.com

# è·å– token
sudo cat /var/lib/rancher/k3s/server/node-token

# ç¬¬äºŒã€ä¸‰ä¸ªä¸»èŠ‚ç‚¹ï¼ˆåŠ å…¥é›†ç¾¤ï¼‰
curl -sfL https://get.k3s.io | sh -s - server \
  --server https://first-server:6443 \
  --token=K10xxx...

# æ·»åŠ  Agent èŠ‚ç‚¹
curl -sfL https://get.k3s.io | K3S_URL=https://k3s-lb.example.com:6443 \
  K3S_TOKEN=K10xxx... sh -
```

### 4.3 ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“

```bash
# PostgreSQL
curl -sfL https://get.k3s.io | sh -s - server \
  --datastore-endpoint="postgres://user:pass@hostname:5432/k3s"

# MySQL
curl -sfL https://get.k3s.io | sh -s - server \
  --datastore-endpoint="mysql://user:pass@tcp(hostname:3306)/k3s"
```

### 4.4 é…ç½®æ–‡ä»¶æ–¹å¼

```yaml
# /etc/rancher/k3s/config.yaml
write-kubeconfig-mode: "0644"
tls-san:
  - "k3s.example.com"
  - "192.168.1.100"
cluster-cidr: "10.42.0.0/16"
service-cidr: "10.43.0.0/16"
cluster-dns: "10.43.0.10"
disable:
  - traefik
  - servicelb
node-label:
  - "environment=production"
  - "region=us-west"
```

```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶å®‰è£…
curl -sfL https://get.k3s.io | sh -
```

---

## 5. æ ¸å¿ƒæ¦‚å¿µ

### 5.1 Server vs Agent

**K3s Serverï¼ˆä¸»èŠ‚ç‚¹ï¼‰**
```
åŒ…å«ç»„ä»¶ï¼š
âœ“ API Server
âœ“ Controller Manager
âœ“ Scheduler
âœ“ æ•°æ®å­˜å‚¨
âœ“ Kubelet
âœ“ Kube-proxy

è§’è‰²ï¼š
- é›†ç¾¤æ§åˆ¶å¹³é¢
- è¿è¡Œç³»ç»Ÿ Pod
- å¯åŒæ—¶ä½œä¸º Worker
```

**K3s Agentï¼ˆå·¥ä½œèŠ‚ç‚¹ï¼‰**
```
åŒ…å«ç»„ä»¶ï¼š
âœ“ Kubelet
âœ“ Kube-proxy
âœ“ Containerd

è§’è‰²ï¼š
- è¿è¡Œåº”ç”¨è´Ÿè½½
- æ¥æ”¶ Server è°ƒåº¦
```

### 5.2 æ•°æ®å­˜å‚¨è·¯å¾„

```bash
# K3s æ ¸å¿ƒæ•°æ®ç›®å½•
/var/lib/rancher/k3s/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ db/              # SQLite æ•°æ®åº“
â”‚   â”œâ”€â”€ tls/             # TLS è¯ä¹¦
â”‚   â”œâ”€â”€ manifests/       # è‡ªåŠ¨éƒ¨ç½²çš„æ¸…å•
â”‚   â”œâ”€â”€ token            # é›†ç¾¤ token
â”‚   â””â”€â”€ node-token       # èŠ‚ç‚¹åŠ å…¥ token
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ containerd/      # å®¹å™¨æ•°æ®
â”‚   â”œâ”€â”€ images/          # é•œåƒç¼“å­˜
â”‚   â””â”€â”€ pod-manifests/   # é™æ€ Pod
â””â”€â”€ storage/             # æœ¬åœ° PV å­˜å‚¨

# Kubeconfig
/etc/rancher/k3s/k3s.yaml

# æ—¥å¿—
journalctl -u k3s -f
```

### 5.3 ç½‘ç»œæ¨¡å‹

```
Pod Network (Flannel VXLAN):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node1: 10.42.0.0/24                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”            â”‚
â”‚  â”‚Pod1â”‚  â”‚Pod2â”‚  â”‚Pod3â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ VXLAN Tunnel (Port 8472)
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Node2: 10.42.1.0/24                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”                     â”‚
â”‚  â”‚Pod4â”‚  â”‚Pod5â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Service Network:
  10.43.0.0/16 (ClusterIP)

NodePort Range:
  30000-32767
```

---

## 6. é«˜çº§é…ç½®

### 6.1 è‡ªå®šä¹‰ CNI

```bash
# ç¦ç”¨é»˜è®¤ Flannelï¼Œä½¿ç”¨ Calico
curl -sfL https://get.k3s.io | sh -s - --flannel-backend=none \
  --disable-network-policy

# å®‰è£… Calico
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

### 6.2 ç§æœ‰é•œåƒä»“åº“

```bash
# /etc/rancher/k3s/registries.yaml
mirrors:
  docker.io:
    endpoint:
      - "https://registry.example.com"
  registry.example.com:
    endpoint:
      - "https://registry.example.com"

configs:
  "registry.example.com":
    auth:
      username: admin
      password: password
    tls:
      cert_file: /path/to/cert.crt
      key_file: /path/to/cert.key
      ca_file: /path/to/ca.crt
```

```bash
# é‡å¯ K3s ä½¿é…ç½®ç”Ÿæ•ˆ
sudo systemctl restart k3s
```

### 6.3 è‡ªåŠ¨éƒ¨ç½²æ¸…å•

K3s ä¼šè‡ªåŠ¨éƒ¨ç½² `/var/lib/rancher/k3s/server/manifests/` ä¸‹çš„ YAML æ–‡ä»¶ï¼š

```bash
# /var/lib/rancher/k3s/server/manifests/my-app.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: my-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-daemon
  namespace: my-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: my-daemon
  template:
    metadata:
      labels:
        app: my-daemon
    spec:
      containers:
      - name: daemon
        image: my-image:latest
```

**æ³¨æ„ï¼š** åˆ é™¤è¯¥æ–‡ä»¶ä¼šè‡ªåŠ¨åˆ é™¤èµ„æºï¼

### 6.4 èµ„æºé™åˆ¶

```yaml
# /etc/rancher/k3s/config.yaml
kubelet-arg:
  - "max-pods=50"
  - "eviction-hard=memory.available<500Mi"
  - "eviction-hard=nodefs.available<10%"
  - "kube-reserved=cpu=200m,memory=500Mi"
  - "system-reserved=cpu=200m,memory=500Mi"
```

### 6.5 å¤‡ä»½ä¸æ¢å¤

```bash
# å¤‡ä»½ï¼ˆSQLiteï¼‰
sudo cp /var/lib/rancher/k3s/server/db/state.db \
  /backup/k3s-state-$(date +%F).db

# å¤‡ä»½ï¼ˆetcdï¼‰
sudo k3s etcd-snapshot save --name backup-$(date +%F)

# åˆ—å‡ºå¿«ç…§
sudo k3s etcd-snapshot ls

# æ¢å¤
sudo k3s server \
  --cluster-reset \
  --cluster-reset-restore-path=/var/lib/rancher/k3s/server/db/snapshots/backup-2024-01-01
```

---

## 7. å¤æ‚å®æˆ˜æ¡ˆä¾‹ï¼šå¾®æœåŠ¡ç”µå•†å¹³å°

### 7.0 æ¶æ„æ¦‚è¿°

æœ¬æ¡ˆä¾‹æ„å»ºä¸€ä¸ª**ç”Ÿäº§çº§å¾®æœåŠ¡ç”µå•†å¹³å°**ï¼Œå®Œæ•´å±•ç¤º K3s çš„ä¼ä¸šåº”ç”¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ ˆï¼š**
```
å‰ç«¯å±‚ï¼šReact SPA + Nginx
ç½‘å…³å±‚ï¼šTraefik Ingressï¼ˆK3s é»˜è®¤ï¼‰
æœåŠ¡å±‚ï¼šç”¨æˆ·æœåŠ¡(Go) + å•†å“æœåŠ¡(Node.js) + è®¢å•æœåŠ¡(Python)
ä¸­é—´ä»¶ï¼šPostgreSQL + Redis + RabbitMQ
ç›‘æ§å±‚ï¼šPrometheus + Grafana + Metrics Server
```

**ç³»ç»Ÿæ¶æ„ï¼š**
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Internet   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Traefik    â”‚ (Ingress Controller)
                    â”‚  LoadBalancerâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
        â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend    â”‚                   â”‚  API Services  â”‚
â”‚  (React SPA)  â”‚                   â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                    â”‚ â”‚User Serviceâ”‚ â”‚
                                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                    â”‚ â”‚Prod Serviceâ”‚ â”‚
                                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                    â”‚ â”‚Order Svc   â”‚ â”‚
                                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
                          â–¼                  â–¼                â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ PostgreSQL   â”‚  â”‚    Redis     â”‚  â”‚  RabbitMQ    â”‚
                  â”‚  (Database)  â”‚  â”‚   (Cache)    â”‚  â”‚ (Message Q)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**éƒ¨ç½²æ‹“æ‰‘ï¼š**
- 3 èŠ‚ç‚¹é«˜å¯ç”¨ K3s é›†ç¾¤ï¼ˆåµŒå…¥å¼ etcdï¼‰
- è·¨å‘½åç©ºé—´éš”ç¦»ï¼ˆprodã€middlewareã€monitoringï¼‰
- è‡ªåŠ¨æ‰©ç¼©å®¹ï¼ˆHPAï¼‰
- æ»šåŠ¨æ›´æ–°é›¶åœæœº

### 7.1 é›†ç¾¤åˆå§‹åŒ–

```bash
# ä¸‰èŠ‚ç‚¹é«˜å¯ç”¨é›†ç¾¤ï¼ˆåµŒå…¥å¼ etcdï¼‰
# node1 (Master 1)
curl -sfL https://get.k3s.io | sh -s - server \
  --cluster-init \
  --tls-san=k3s.ecommerce.local \
  --write-kubeconfig-mode=644 \
  --disable=servicelb

# ç­‰å¾…ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å°±ç»ª
sudo k3s kubectl get nodes

# è·å– tokenï¼ˆåœ¨ node1 ä¸Šæ‰§è¡Œï¼‰
NODE_TOKEN=$(sudo cat /var/lib/rancher/k3s/server/node-token)
echo $NODE_TOKEN  # å¤åˆ¶æ­¤ token

# node2 (Master 2) - ä½¿ç”¨ä¸Šé¢è·å–çš„ token
curl -sfL https://get.k3s.io | sh -s - server \
  --server https://node1:6443 \
  --token=K10xxx... \
  --tls-san=k3s.ecommerce.local

# node3 (Master 3)
curl -sfL https://get.k3s.io | sh -s - server \
  --server https://node1:6443 \
  --token=K10xxx... \
  --tls-san=k3s.ecommerce.local

# éªŒè¯é›†ç¾¤çŠ¶æ€
sudo k3s kubectl get nodes
# åº”è¯¥çœ‹åˆ° 3 ä¸ª master èŠ‚ç‚¹ï¼Œéƒ½æ˜¯ Ready çŠ¶æ€

# å®‰è£… Metrics Serverï¼ˆHPA å¿…éœ€ï¼‰
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# é…ç½® Metrics Serverï¼ˆK3s éœ€è¦ç¦ç”¨ TLS éªŒè¯ï¼‰
kubectl patch deployment metrics-server -n kube-system --type='json' \
  -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'
```

### 7.2 é¡¹ç›®ç»“æ„ä¸å‡†å¤‡

#### 7.2.1 ç›®å½•ç»“æ„

```bash
k3s-ecommerce/
â”œâ”€â”€ infrastructure/          # åŸºç¡€è®¾æ–½é…ç½®
â”‚   â”œâ”€â”€ namespaces.yaml     # å‘½åç©ºé—´å®šä¹‰
â”‚   â”œâ”€â”€ secrets.yaml        # æ ¸å¿ƒå¯†é’¥é…ç½®
â”‚   â”œâ”€â”€ rbac.yaml          # RBAC æƒé™é…ç½®
â”‚   â”œâ”€â”€ storage-class.yaml  # å­˜å‚¨ç±»é…ç½®
â”‚   â””â”€â”€ network-policies.yaml  # ç½‘ç»œç­–ç•¥
â”œâ”€â”€ middleware/             # ä¸­é—´ä»¶å±‚
â”‚   â”œâ”€â”€ postgresql/         # æ•°æ®åº“
â”‚   â”‚   â””â”€â”€ statefulset.yaml
â”‚   â”œâ”€â”€ redis/              # ç¼“å­˜
â”‚   â”‚   â””â”€â”€ deployment.yaml
â”‚   â””â”€â”€ rabbitmq/           # æ¶ˆæ¯é˜Ÿåˆ—
â”‚       â””â”€â”€ statefulset.yaml
â”œâ”€â”€ services/               # å¾®æœåŠ¡å±‚
â”‚   â”œâ”€â”€ user-service/       # ç”¨æˆ·æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â””â”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ product-service/    # å•†å“æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â””â”€â”€ service.yaml
â”‚   â””â”€â”€ order-service/      # è®¢å•æœåŠ¡
â”‚       â”œâ”€â”€ deployment.yaml
â”‚       â””â”€â”€ service.yaml
â”œâ”€â”€ gateway/                # ç½‘å…³å±‚
â”‚   â””â”€â”€ ingress.yaml        # Ingress è·¯ç”±é…ç½®
â”œâ”€â”€ frontend/               # å‰ç«¯
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â””â”€â”€ service.yaml
â”œâ”€â”€ monitoring/             # ç›‘æ§ç³»ç»Ÿ
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â””â”€â”€ deployment.yaml
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ deployment.yaml
â”œâ”€â”€ deploy.sh               # ä¸€é”®éƒ¨ç½²è„šæœ¬
â””â”€â”€ README.md               # éƒ¨ç½²è¯´æ˜
```

#### 7.2.2 å¿«é€Ÿå¼€å§‹

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p k3s-ecommerce/{infrastructure,middleware/{postgresql,redis,rabbitmq},services/{user-service,product-service,order-service},gateway,frontend,monitoring/{prometheus,grafana}}

cd k3s-ecommerce

# 2. å°†ä¸‹é¢å„èŠ‚çš„ YAML å†…å®¹ä¿å­˜åˆ°å¯¹åº”æ–‡ä»¶

# 3. åˆ›å»ºéƒ¨ç½²è„šæœ¬
cat > deploy.sh << 'EOF'
# ... (éƒ¨ç½²è„šæœ¬å†…å®¹è§ 7.9 èŠ‚)
EOF

chmod +x deploy.sh

# 4. æ‰§è¡Œéƒ¨ç½²
./deploy.sh

# 5. é…ç½®æœ¬åœ° hostsï¼ˆmacOS/Linuxï¼‰
sudo bash -c 'cat >> /etc/hosts << EOF
127.0.0.1  ecommerce.local
127.0.0.1  grafana.local
127.0.0.1  prometheus.local
EOF'

# Windows ç”¨æˆ·ç¼–è¾‘: C:\Windows\System32\drivers\etc\hosts
```

#### 7.2.3 å‰ç½®è¦æ±‚

```bash
# ç³»ç»Ÿè¦æ±‚
- æœ€ä½ 2 æ ¸ 4GB å†…å­˜
- æ¨è 4 æ ¸ 8GB å†…å­˜ï¼ˆç”¨äºå®Œæ•´æµ‹è¯•ï¼‰
- 20GB å¯ç”¨ç£ç›˜ç©ºé—´

# è½¯ä»¶è¦æ±‚
- K3s v1.27+
- kubectl å®¢æˆ·ç«¯
- curl (ç”¨äºæµ‹è¯•)

# éªŒè¯ç¯å¢ƒ
kubectl version
kubectl get nodes
kubectl cluster-info
```

### 7.3 åŸºç¡€è®¾æ–½é…ç½®

#### 7.3.1 å‘½åç©ºé—´

```yaml
# infrastructure/namespaces.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: ecommerce-prod
  labels:
    environment: production
---
apiVersion: v1
kind: Namespace
metadata:
  name: ecommerce-middleware
  labels:
    tier: middleware
---
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
```

#### 7.3.2 æ ¸å¿ƒ Secrets

```yaml
# infrastructure/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: database-config
  namespace: ecommerce-prod
type: Opaque
stringData:
  user-db-url: "postgresql://ecommerce_user:ChangeMe123!@postgresql.ecommerce-middleware:5432/users"
  product-db-url: "postgresql://ecommerce_user:ChangeMe123!@postgresql.ecommerce-middleware:5432/products"
  order-db-url: "postgresql://ecommerce_user:ChangeMe123!@postgresql.ecommerce-middleware:5432/orders"
---
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secret
  namespace: ecommerce-prod
type: Opaque
stringData:
  secret: "your-super-secret-jwt-key-change-in-production"
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-secret
  namespace: monitoring
type: Opaque
stringData:
  admin-password: "admin123"
```

#### 7.3.3 RBAC é…ç½®

```yaml
# infrastructure/rbac.yaml
# Prometheus ServiceAccount å’Œæƒé™
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
```

#### 7.3.4 å­˜å‚¨ç±»

```yaml

```yaml
# infrastructure/storage-class.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-path
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rancher.io/local-path
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
```

```yaml
# infrastructure/network-policies.yaml
# æ³¨æ„ï¼šä»…ç”¨äºæ¼”ç¤ºç½‘ç»œç­–ç•¥æ¦‚å¿µï¼Œç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´ç²¾ç»†çš„è§„åˆ™

# å…è®¸æœåŠ¡è®¿é—®ä¸­é—´ä»¶å‘½åç©ºé—´çš„æ•°æ®åº“å’Œç¼“å­˜
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-from-prod
  namespace: ecommerce-middleware
spec:
  podSelector:
    matchLabels:
      tier: database
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          environment: production
    ports:
    - protocol: TCP
      port: 5432
    - protocol: TCP
      port: 6379
    - protocol: TCP
      port: 5672
---
# å…è®¸æ‰€æœ‰ Egressï¼ˆç®€åŒ–é…ç½®ï¼‰
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-all-egress
  namespace: ecommerce-prod
spec:
  podSelector: {}
  policyTypes:
  - Egress
  egress:
  - {}
---
# å…è®¸ Ingress æ§åˆ¶å™¨è®¿é—®æœåŠ¡
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-ingress-to-services
  namespace: ecommerce-prod
spec:
  podSelector:
    matchLabels:
      tier: frontend
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: TCP
      port: 80
```

### 7.4 ä¸­é—´ä»¶éƒ¨ç½²

```yaml
# middleware/postgresql/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
  namespace: ecommerce-middleware
spec:
  serviceName: postgresql
  replicas: 1
  selector:
    matchLabels:
      app: postgresql
  template:
    metadata:
      labels:
        app: postgresql
        tier: database
    spec:
      containers:
      - name: postgresql
        image: postgres:15-alpine
        env:
        - name: POSTGRES_DB
          value: ecommerce
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        ports:
        - containerPort: 5432
          name: postgresql
        volumeMounts:
        - name: data
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-path
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  namespace: ecommerce-middleware
spec:
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432
  clusterIP: None
---
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: ecommerce-middleware
type: Opaque
stringData:
  username: ecommerce_user
  password: "ChangeMe123!"
```

```yaml
# middleware/redis/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: ecommerce-middleware
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
        tier: cache
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        command:
        - redis-server
        - --appendonly yes
        - --requirepass $(REDIS_PASSWORD)
        env:
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: password
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
      volumes:
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: ecommerce-middleware
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
---
apiVersion: v1
kind: Secret
metadata:
  name: redis-secret
  namespace: ecommerce-middleware
type: Opaque
stringData:
  password: "RedisPass123!"
```

```yaml
# middleware/rabbitmq/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: rabbitmq
  namespace: ecommerce-middleware
spec:
  serviceName: rabbitmq
  replicas: 1
  selector:
    matchLabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
        tier: messaging
    spec:
      containers:
      - name: rabbitmq
        image: rabbitmq:3.12-management-alpine
        env:
        - name: RABBITMQ_DEFAULT_USER
          value: admin
        - name: RABBITMQ_DEFAULT_PASS
          valueFrom:
            secretKeyRef:
              name: rabbitmq-secret
              key: password
        ports:
        - containerPort: 5672
          name: amqp
        - containerPort: 15672
          name: management
        volumeMounts:
        - name: data
          mountPath: /var/lib/rabbitmq
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "400m"
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      storageClassName: local-path
      resources:
        requests:
          storage: 5Gi
---
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq
  namespace: ecommerce-middleware
spec:
  selector:
    app: rabbitmq
  ports:
  - port: 5672
    targetPort: 5672
    name: amqp
  - port: 15672
    targetPort: 15672
    name: management
---
apiVersion: v1
kind: Secret
metadata:
  name: rabbitmq-secret
  namespace: ecommerce-middleware
type: Opaque
stringData:
  password: "RabbitPass123!"
```

### 7.5 å¾®æœåŠ¡éƒ¨ç½²

```yaml
# services/user-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
  namespace: ecommerce-prod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
        tier: backend
        version: v1
    spec:
      containers:
      - name: user-service
        image: your-registry/user-service:1.0.0
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-config
              key: user-db-url
        - name: REDIS_URL
          value: redis://redis.ecommerce-middleware:6379
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: password
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: secret
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: user-service-config
              key: log_level
        ports:
        - containerPort: 8080
          name: http
        - containerPort: 9090
          name: metrics
        livenessProbe:
          httpGet:
            path: /health/live
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
apiVersion: v1
kind: Service
metadata:
  name: user-service
  namespace: ecommerce-prod
  labels:
    app: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 80
    targetPort: 8080
    name: http
  - port: 9090
    targetPort: 9090
    name: metrics
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: user-service-config
  namespace: ecommerce-prod
data:
  log_level: "info"
  rate_limit: "100"
  cache_ttl: "3600"
```

```yaml
# services/user-service/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
  namespace: ecommerce-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 2
        periodSeconds: 30
      selectPolicy: Max
```

```yaml
# services/product-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: product-service
  namespace: ecommerce-prod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: product-service
  template:
    metadata:
      labels:
        app: product-service
        tier: backend
        version: v1
    spec:
      containers:
      - name: product-service
        image: your-registry/product-service:1.0.0
        env:
        - name: NODE_ENV
          value: production
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-config
              key: product-db-url
        - name: REDIS_URL
          value: redis://redis.ecommerce-middleware:6379
        - name: ELASTICSEARCH_URL
          value: http://elasticsearch:9200
        ports:
        - containerPort: 3000
          name: http
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: product-service
  namespace: ecommerce-prod
spec:
  selector:
    app: product-service
  ports:
  - port: 80
    targetPort: 3000
```

```yaml
# services/order-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: order-service
  namespace: ecommerce-prod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: order-service
  template:
    metadata:
      labels:
        app: order-service
        tier: backend
        version: v1
    spec:
      containers:
      - name: order-service
        image: your-registry/order-service:1.0.0
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-config
              key: order-db-url
        - name: RABBITMQ_URL
          value: amqp://admin:RabbitPass123!@rabbitmq.ecommerce-middleware:5672
        - name: PAYMENT_SERVICE_URL
          value: http://payment-service
        ports:
        - containerPort: 8000
          name: http
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: order-service
  namespace: ecommerce-prod
spec:
  selector:
    app: order-service
  ports:
  - port: 80
    targetPort: 8000
```

### 7.6 Ingress é…ç½®ï¼ˆä½¿ç”¨ Traefikï¼‰

K3s é»˜è®¤é›†æˆ Traefikï¼Œæˆ‘ä»¬ä½¿ç”¨ IngressRoute é…ç½®è·¯ç”±å’Œä¸­é—´ä»¶ã€‚

```yaml
# gateway/ingress.yaml
# ä¸»åº”ç”¨ Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ecommerce-ingress
  namespace: ecommerce-prod
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: web,websecure
    traefik.ingress.kubernetes.io/router.middlewares: ecommerce-prod-rate-limit@kubernetescrd
spec:
  rules:
  - host: ecommerce.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 80
      - path: /api/users
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 80
      - path: /api/products
        pathType: Prefix
        backend:
          service:
            name: product-service
            port:
              number: 80
      - path: /api/orders
        pathType: Prefix
        backend:
          service:
            name: order-service
            port:
              number: 80
---
# Traefik ä¸­é—´ä»¶ - é™æµ
apiVersion: traefik.containo.us/v1alpha1
kind: Middleware
metadata:
  name: rate-limit
  namespace: ecommerce-prod
spec:
  rateLimit:
    average: 100
    burst: 50
---
# Traefik ä¸­é—´ä»¶ - CORS
apiVersion: traefik.containo.us/v1alpha1
kind: Middleware
metadata:
  name: cors
  namespace: ecommerce-prod
spec:
  headers:
    accessControlAllowMethods:
      - GET
      - POST
      - PUT
      - DELETE
    accessControlAllowOriginList:
      - "*"
    accessControlMaxAge: 100
    addVaryHeader: true
---
# ç›‘æ§ Dashboard Ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: monitoring-ingress
  namespace: monitoring
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: web
spec:
  rules:
  - host: grafana.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: grafana
            port:
              number: 3000
  - host: prometheus.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: prometheus
            port:
              number: 9090
```

### 7.7 å‰ç«¯éƒ¨ç½²

```yaml
# frontend/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
  namespace: ecommerce-prod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: your-registry/ecommerce-frontend:1.0.0
        ports:
        - containerPort: 80
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
      volumes:
      - name: nginx-config
        configMap:
          name: nginx-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: ecommerce-prod
data:
  nginx.conf: |
    user nginx;
    worker_processes auto;

    events {
      worker_connections 1024;
    }

    http {
      include /etc/nginx/mime.types;
      default_type application/octet-stream;

      gzip on;
      gzip_types text/plain text/css application/json application/javascript;

      server {
        listen 80;
        root /usr/share/nginx/html;
        index index.html;

        location / {
          try_files $uri $uri/ /index.html;
        }

        # API è¯·æ±‚é€šè¿‡ Ingress è·¯ç”±ï¼Œå‰ç«¯åªéœ€æä¾›é™æ€æ–‡ä»¶
        location /api {
          return 404 "API should be accessed via ingress";
        }
      }
    }
---
apiVersion: v1
kind: Service
metadata:
  name: frontend
  namespace: ecommerce-prod
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 80
```

**æ³¨æ„ï¼š** Ingress é…ç½®å·²åœ¨ `gateway/ingress.yaml` ä¸­ç»Ÿä¸€å®šä¹‰ã€‚

### 7.8 ç›‘æ§ç³»ç»Ÿ

```yaml
# monitoring/prometheus/deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    scrape_configs:
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__

      - job_name: 'user-service'
        static_configs:
        - targets: ['user-service.ecommerce-prod:9090']

      - job_name: 'apisix'
        static_configs:
        - targets: ['apisix.ecommerce-prod:9091']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: prom/prometheus:v2.48.0
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--storage.tsdb.retention.time=30d'
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
      volumes:
      - name: config
        configMap:
          name: prometheus-config
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
```

```yaml
# monitoring/grafana/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:10.2.0
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grafana-secret
              key: admin-password
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel"
        ports:
        - containerPort: 3000
        volumeMounts:
        - name: data
          mountPath: /var/lib/grafana
        - name: datasources
          mountPath: /etc/grafana/provisioning/datasources
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: data
        emptyDir: {}
      - name: datasources
        configMap:
          name: grafana-datasources
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
    - name: Prometheus
      type: prometheus
      access: proxy
      url: http://prometheus:9090
      isDefault: true
    - name: Loki
      type: loki
      access: proxy
      url: http://loki:3100
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: monitoring
spec:
  selector:
    app: grafana
  ports:
  - port: 3000
    targetPort: 3000
  type: ClusterIP
```

### 7.9 éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh - å®Œæ•´éƒ¨ç½²è„šæœ¬

set -e

echo "ğŸš€ å¼€å§‹éƒ¨ç½² K3s ç”µå•†å¹³å°"
echo "================================"

# æ£€æŸ¥ kubectl å¯ç”¨æ€§
if ! command -v kubectl &> /dev/null; then
    echo "âŒ kubectl æœªå®‰è£…æˆ–ä¸åœ¨ PATH ä¸­"
    exit 1
fi

# 1. åˆ›å»ºå‘½åç©ºé—´
echo ""
echo "ğŸ“¦ æ­¥éª¤ 1/8: åˆ›å»ºå‘½åç©ºé—´..."
kubectl apply -f infrastructure/namespaces.yaml

# 2. åˆ›å»º RBAC å’Œ Secrets
echo ""
echo "ğŸ” æ­¥éª¤ 2/8: é…ç½® RBAC å’Œ Secrets..."
kubectl apply -f infrastructure/rbac.yaml
kubectl apply -f infrastructure/secrets.yaml

# 3. é…ç½®å­˜å‚¨å’Œç½‘ç»œ
echo ""
echo "ğŸ’¾ æ­¥éª¤ 3/8: é…ç½®å­˜å‚¨ç±»å’Œç½‘ç»œç­–ç•¥..."
kubectl apply -f infrastructure/storage-class.yaml
kubectl apply -f infrastructure/network-policies.yaml

# 4. éƒ¨ç½²ä¸­é—´ä»¶
echo ""
echo "ğŸ—„ï¸  æ­¥éª¤ 4/8: éƒ¨ç½²æ•°æ®åº“å’Œæ¶ˆæ¯é˜Ÿåˆ—..."
kubectl apply -f middleware/postgresql/
kubectl apply -f middleware/redis/
kubectl apply -f middleware/rabbitmq/

# ç­‰å¾…ä¸­é—´ä»¶å°±ç»ª
echo "â³ ç­‰å¾…ä¸­é—´ä»¶å¯åŠ¨..."
kubectl wait --for=condition=ready pod -l app=postgresql -n ecommerce-middleware --timeout=300s 2>/dev/null || true
kubectl wait --for=condition=ready pod -l app=redis -n ecommerce-middleware --timeout=300s 2>/dev/null || true
kubectl wait --for=condition=ready pod -l app=rabbitmq -n ecommerce-middleware --timeout=300s 2>/dev/null || true

echo "âœ… ä¸­é—´ä»¶éƒ¨ç½²å®Œæˆ"

# 5. éƒ¨ç½²å¾®æœåŠ¡
echo ""
echo "ğŸ”§ æ­¥éª¤ 5/8: éƒ¨ç½²å¾®æœåŠ¡..."
kubectl apply -f services/user-service/
kubectl apply -f services/product-service/
kubectl apply -f services/order-service/

# ç­‰å¾…æœåŠ¡å°±ç»ª
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 10

# 6. éƒ¨ç½²å‰ç«¯
echo ""
echo "ğŸ¨ æ­¥éª¤ 6/8: éƒ¨ç½²å‰ç«¯..."
kubectl apply -f frontend/

# 7. é…ç½® Ingress
echo ""
echo "ğŸŒ æ­¥éª¤ 7/8: é…ç½® Ingress è·¯ç”±..."
kubectl apply -f gateway/ingress.yaml

# 8. éƒ¨ç½²ç›‘æ§
echo ""
echo "ğŸ“Š æ­¥éª¤ 8/8: éƒ¨ç½²ç›‘æ§ç³»ç»Ÿ..."
kubectl apply -f monitoring/prometheus/
kubectl apply -f monitoring/grafana/

echo ""
echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "================================"
echo ""
echo "ğŸ“‹ è®¿é—®ä¿¡æ¯ï¼š"
echo "--------------------------------"
echo "éœ€è¦åœ¨ /etc/hosts æ·»åŠ ä»¥ä¸‹è®°å½•ï¼š"
echo ""
echo "127.0.0.1  ecommerce.local"
echo "127.0.0.1  grafana.local"
echo "127.0.0.1  prometheus.local"
echo ""
echo "è®¿é—®åœ°å€ï¼š"
echo "  ğŸŒ å‰ç«¯: http://ecommerce.local"
echo "  ğŸ“Š Grafana: http://grafana.local (admin/admin123)"
echo "  ğŸ“ˆ Prometheus: http://prometheus.local"
echo ""
echo "æ£€æŸ¥éƒ¨ç½²çŠ¶æ€ï¼š"
echo "  kubectl get pods -n ecommerce-prod"
echo "  kubectl get pods -n ecommerce-middleware"
echo "  kubectl get pods -n monitoring"
echo ""
echo "æŸ¥çœ‹ Traefik Dashboard:"
echo "  kubectl port-forward -n kube-system \$(kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik -o name) 9000:9000"
echo "  è®¿é—®: http://localhost:9000/dashboard/"
```

### 7.10 æ¶æ„å†³ç­–è¯´æ˜

#### ä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›æŠ€æœ¯ï¼Ÿ

**1. ä½¿ç”¨ Traefik è€Œéå…¶ä»– Ingress Controller**
- âœ… K3s é»˜è®¤é›†æˆï¼Œé›¶é…ç½®å³å¯ä½¿ç”¨
- âœ… æ”¯æŒåŠ¨æ€é…ç½®ï¼Œæ— éœ€é‡å¯
- âœ… åŸç”Ÿæ”¯æŒ Kubernetes CRDï¼ˆMiddlewareã€IngressRouteï¼‰
- âœ… å†…ç½® Dashboard å’Œ Metrics
- âœ… èµ„æºå ç”¨ä½ï¼ˆ~50MB å†…å­˜ï¼‰

**2. PostgreSQL å•å®ä¾‹éƒ¨ç½²**
- æœ¬ demo ä¾§é‡å±•ç¤º K8s éƒ¨ç½²ï¼Œæ•°æ®åº“é«˜å¯ç”¨éœ€è¦ Patroni/Stolon ç­‰å¤æ‚æ–¹æ¡ˆ
- ç”Ÿäº§ç¯å¢ƒå»ºè®®ï¼š
  - ä½¿ç”¨äº‘æ•°æ®åº“ï¼ˆRDS/Cloud SQLï¼‰
  - æˆ–éƒ¨ç½² PostgreSQL Operatorï¼ˆZalandoã€Crunchy Dataï¼‰

**3. Redis å•å®ä¾‹ + emptyDir**
- ç¼“å­˜æ•°æ®å¯ä»¥ä¸¢å¤±ï¼Œé‡å¯åé‡å»º
- ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ï¼š
  - Redis Sentinelï¼ˆé«˜å¯ç”¨ï¼‰
  - Redis Clusterï¼ˆåˆ†ç‰‡ï¼‰
  - æŒä¹…åŒ–å­˜å‚¨ï¼ˆPVCï¼‰

**4. ä¸ä½¿ç”¨æœåŠ¡ç½‘æ ¼ï¼ˆIstio/Linkerdï¼‰**
- æœ¬æ¡ˆä¾‹è§„æ¨¡è¾ƒå°ï¼ŒæœåŠ¡ç½‘æ ¼ä¼šå¢åŠ å¤æ‚åº¦
- Traefik Middleware å·²æ»¡è¶³åŸºæœ¬éœ€æ±‚ï¼ˆé™æµã€é‡è¯•ã€CORSï¼‰
- å¤§è§„æ¨¡å¾®æœåŠ¡ï¼ˆ50+ æœåŠ¡ï¼‰æ‰è€ƒè™‘æœåŠ¡ç½‘æ ¼

**5. Metrics Server vs Prometheus Adapter**
- Metrics Serverï¼šæä¾›åŸºç¡€ CPU/å†…å­˜æŒ‡æ ‡ï¼Œè¶³å¤Ÿç®€å• HPA
- Prometheus Adapterï¼šæ”¯æŒè‡ªå®šä¹‰æŒ‡æ ‡ï¼ˆQPSã€å»¶è¿Ÿç­‰ï¼‰
- æœ¬æ¡ˆä¾‹ä½¿ç”¨ Metrics Serverï¼Œç®€å•å®ç”¨

#### æˆæœ¬ä¼˜åŒ–å»ºè®®

```yaml
# èµ„æºé™åˆ¶å»ºè®®ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
å°å‹éƒ¨ç½²ï¼ˆ< 1000 ç”¨æˆ·ï¼‰:
  - å¾®æœåŠ¡: requests: 100m/128Mi, limits: 200m/256Mi
  - æ•°æ®åº“: requests: 500m/1Gi, limits: 1/2Gi
  - æ€»éœ€æ±‚: 4 æ ¸ 8GB

ä¸­å‹éƒ¨ç½²ï¼ˆ< 10000 ç”¨æˆ·ï¼‰:
  - å¾®æœåŠ¡: requests: 200m/256Mi, limits: 500m/512Mi
  - æ•°æ®åº“: requests: 1/2Gi, limits: 2/4Gi
  - æ€»éœ€æ±‚: 8 æ ¸ 16GB

å¤§å‹éƒ¨ç½²ï¼ˆ> 10000 ç”¨æˆ·ï¼‰:
  - ä½¿ç”¨ HPA è‡ªåŠ¨æ‰©å®¹
  - åˆ†ç¦»æ•°æ®åº“åˆ°ç‹¬ç«‹é›†ç¾¤
  - è€ƒè™‘å¤šåŒºåŸŸéƒ¨ç½²
```

### 7.11 éªŒè¯å’Œæµ‹è¯•

#### éƒ¨ç½²éªŒè¯

```bash
# æ£€æŸ¥æ‰€æœ‰ Pod çŠ¶æ€
kubectl get pods -A

# æŸ¥çœ‹ Ingress é…ç½®
kubectl get ingress -A

# æ£€æŸ¥ Traefik çŠ¶æ€
kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik

# æŸ¥çœ‹æœåŠ¡æš´éœ²æƒ…å†µ
kubectl get svc -n ecommerce-prod
kubectl get svc -n ecommerce-middleware
kubectl get svc -n monitoring
```

#### åŠŸèƒ½æµ‹è¯•

```bash
# 1. æµ‹è¯•ç”¨æˆ·æœåŠ¡ï¼ˆå†…éƒ¨è®¿é—®ï¼‰
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://user-service.ecommerce-prod/health

# 2. æµ‹è¯•äº§å“æœåŠ¡
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://product-service.ecommerce-prod/health

# 3. æµ‹è¯•è®¢å•æœåŠ¡
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://order-service.ecommerce-prod/health

# 4. æµ‹è¯•é€šè¿‡ Ingress è®¿é—®ï¼ˆéœ€è¦å…ˆé…ç½® hostsï¼‰
# åœ¨å®¿ä¸»æœºæ·»åŠ : 127.0.0.1 ecommerce.local
curl http://ecommerce.local/

# 5. æµ‹è¯• API è·¯ç”±
curl http://ecommerce.local/api/users/health
curl http://ecommerce.local/api/products/health
curl http://ecommerce.local/api/orders/health
```

#### æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹å¾®æœåŠ¡æ—¥å¿—
kubectl logs -f deployment/user-service -n ecommerce-prod
kubectl logs -f deployment/product-service -n ecommerce-prod
kubectl logs -f deployment/order-service -n ecommerce-prod

# æŸ¥çœ‹ä¸­é—´ä»¶æ—¥å¿—
kubectl logs -f statefulset/postgresql -n ecommerce-middleware
kubectl logs -f deployment/redis -n ecommerce-middleware
kubectl logs -f statefulset/rabbitmq -n ecommerce-middleware

# æŸ¥çœ‹ Traefik æ—¥å¿—
kubectl logs -f -n kube-system -l app.kubernetes.io/name=traefik
```

#### æ€§èƒ½ç›‘æ§

```bash
# æŸ¥çœ‹èµ„æºä½¿ç”¨ï¼ˆéœ€è¦ Metrics Serverï¼‰
kubectl top nodes
kubectl top pods -n ecommerce-prod
kubectl top pods -n ecommerce-middleware

# æŸ¥çœ‹ HPA çŠ¶æ€
kubectl get hpa -n ecommerce-prod

# æŸ¥çœ‹ HPA è¯¦æƒ…
kubectl describe hpa user-service-hpa -n ecommerce-prod
```

#### å‹åŠ›æµ‹è¯•

```bash
# å®‰è£…æµ‹è¯•å·¥å…·
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: loadtest
  namespace: ecommerce-prod
spec:
  containers:
  - name: wrk
    image: williamyeh/wrk
    command: ["sleep", "3600"]
EOF

# ç­‰å¾… Pod å°±ç»ª
kubectl wait --for=condition=ready pod/loadtest -n ecommerce-prod

# æ‰§è¡Œå‹åŠ›æµ‹è¯•
kubectl exec -it loadtest -n ecommerce-prod -- \
  wrk -t4 -c100 -d30s http://user-service/health

# æµ‹è¯• Ingressï¼ˆä»é›†ç¾¤å¤–éƒ¨ï¼‰
# éœ€è¦åœ¨å®¿ä¸»æœºæ‰§è¡Œ
wrk -t4 -c100 -d30s http://ecommerce.local/api/products

# æ¸…ç†æµ‹è¯• Pod
kubectl delete pod loadtest -n ecommerce-prod
```

#### ç›‘æ§è®¿é—®

```bash
# æ–¹æ³• 1ï¼šé€šè¿‡ Ingress è®¿é—®ï¼ˆæ¨èï¼‰
# æµè§ˆå™¨æ‰“å¼€ http://grafana.local
# ç”¨æˆ·å: admin, å¯†ç : admin123

# æ–¹æ³• 2ï¼šé€šè¿‡ Port-forward è®¿é—®
kubectl port-forward -n monitoring svc/grafana 3000:3000
# è®¿é—® http://localhost:3000

kubectl port-forward -n monitoring svc/prometheus 9090:9090
# è®¿é—® http://localhost:9090
```

#### æ•…éšœæ¨¡æ‹Ÿæµ‹è¯•

```bash
# 1. åˆ é™¤ä¸€ä¸ª Podï¼Œæµ‹è¯•è‡ªåŠ¨æ¢å¤
kubectl delete pod -n ecommerce-prod -l app=user-service --force
kubectl get pods -n ecommerce-prod -w

# 2. æ¨¡æ‹Ÿé«˜è´Ÿè½½ï¼Œæµ‹è¯• HPA
kubectl exec -it loadtest -n ecommerce-prod -- \
  wrk -t8 -c200 -d300s http://user-service/health

# è§‚å¯Ÿæ‰©å®¹è¿‡ç¨‹
kubectl get hpa -n ecommerce-prod -w

# 3. æµ‹è¯•æ•°æ®åº“è¿æ¥
kubectl run -it --rm psql --image=postgres:15-alpine --restart=Never -- \
  psql -h postgresql.ecommerce-middleware -U ecommerce_user -d users

# 4. æµ‹è¯• Redis è¿æ¥
kubectl run -it --rm redis-cli --image=redis:7-alpine --restart=Never -- \
  redis-cli -h redis.ecommerce-middleware -a RedisPass123!
```

### 7.12 å¸¸è§é—®é¢˜ï¼ˆFAQï¼‰

#### Q1: ä¸ºä»€ä¹ˆ Pod ä¸€ç›´å¤„äº Pending çŠ¶æ€ï¼Ÿ

```bash
# æŸ¥çœ‹åŸå› 
kubectl describe pod <pod-name> -n <namespace>

# å¸¸è§åŸå› ï¼š
# 1. èµ„æºä¸è¶³
kubectl top nodes  # æŸ¥çœ‹èŠ‚ç‚¹èµ„æº

# 2. PVC æœªç»‘å®š
kubectl get pvc -A

# 3. é•œåƒæ‹‰å–å¤±è´¥
kubectl get events -n <namespace> --sort-by='.lastTimestamp'
```

#### Q2: æœåŠ¡ä¹‹é—´æ— æ³•é€šä¿¡ï¼Ÿ

```bash
# 1. æ£€æŸ¥ç½‘ç»œç­–ç•¥
kubectl get networkpolicy -A

# 2. æµ‹è¯• DNS è§£æ
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  nslookup user-service.ecommerce-prod

# 3. æµ‹è¯•æœåŠ¡è¿é€šæ€§
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://user-service.ecommerce-prod/health

# 4. æ£€æŸ¥ Service ç«¯ç‚¹
kubectl get endpoints -n ecommerce-prod
```

#### Q3: HPA ä¸å·¥ä½œï¼Ÿ

```bash
# 1. æ£€æŸ¥ Metrics Server
kubectl get deployment metrics-server -n kube-system
kubectl top nodes  # åº”è¯¥æœ‰è¾“å‡º

# 2. æ£€æŸ¥ HPA çŠ¶æ€
kubectl get hpa -A
kubectl describe hpa user-service-hpa -n ecommerce-prod

# 3. ç¡®ä¿ Pod è®¾ç½®äº† resources.requests
kubectl get pod <pod-name> -n ecommerce-prod -o yaml | grep -A 5 resources
```

#### Q4: Ingress æ— æ³•è®¿é—®ï¼Ÿ

```bash
# 1. æ£€æŸ¥ Traefik çŠ¶æ€
kubectl get pods -n kube-system -l app.kubernetes.io/name=traefik

# 2. æŸ¥çœ‹ Ingress é…ç½®
kubectl get ingress -A
kubectl describe ingress ecommerce-ingress -n ecommerce-prod

# 3. æ£€æŸ¥ Service
kubectl get svc -n kube-system traefik

# 4. æµ‹è¯•ç«¯å£è½¬å‘
kubectl port-forward -n kube-system svc/traefik 8080:80
curl http://localhost:8080
```

#### Q5: å¦‚ä½•æ¸…ç†æ•´ä¸ªé¡¹ç›®ï¼Ÿ

```bash
# åˆ é™¤æ‰€æœ‰èµ„æº
kubectl delete namespace ecommerce-prod
kubectl delete namespace ecommerce-middleware
kubectl delete namespace monitoring

# æˆ–ä½¿ç”¨è„šæœ¬
cat > cleanup.sh << 'EOF'
#!/bin/bash
echo "âš ï¸  è­¦å‘Šï¼šå°†åˆ é™¤æ‰€æœ‰é¡¹ç›®èµ„æºï¼"
read -p "ç¡®è®¤ç»§ç»­ï¼Ÿ(yes/no): " confirm
if [ "$confirm" != "yes" ]; then
    echo "å–æ¶ˆæ“ä½œ"
    exit 0
fi

echo "åˆ é™¤å‘½åç©ºé—´..."
kubectl delete namespace ecommerce-prod --grace-period=0 --force
kubectl delete namespace ecommerce-middleware --grace-period=0 --force
kubectl delete namespace monitoring --grace-period=0 --force

echo "æ¸…ç† PVCï¼ˆå¦‚æœå­˜åœ¨ï¼‰"
kubectl delete pvc --all -n ecommerce-prod
kubectl delete pvc --all -n ecommerce-middleware

echo "âœ… æ¸…ç†å®Œæˆ"
EOF

chmod +x cleanup.sh
./cleanup.sh
```

#### Q6: å¦‚ä½•æ›´æ–°æœåŠ¡é•œåƒï¼Ÿ

```bash
# æ–¹æ³• 1ï¼šç›´æ¥è®¾ç½®é•œåƒ
kubectl set image deployment/user-service \
  user-service=your-registry/user-service:1.1.0 \
  -n ecommerce-prod

# æ–¹æ³• 2ï¼šç¼–è¾‘ Deployment
kubectl edit deployment user-service -n ecommerce-prod

# æ–¹æ³• 3ï¼šåº”ç”¨æ–°çš„ YAML
kubectl apply -f services/user-service/deployment.yaml

# æŸ¥çœ‹æ»šåŠ¨æ›´æ–°çŠ¶æ€
kubectl rollout status deployment/user-service -n ecommerce-prod

# å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
kubectl rollout undo deployment/user-service -n ecommerce-prod
```

#### Q7: å¦‚ä½•å¤‡ä»½æ•°æ®ï¼Ÿ

```bash
# PostgreSQL å¤‡ä»½
kubectl exec -it postgresql-0 -n ecommerce-middleware -- \
  pg_dump -U ecommerce_user users > backup-users-$(date +%F).sql

# Redis å¤‡ä»½
kubectl exec -it redis-xxx -n ecommerce-middleware -- \
  redis-cli -a RedisPass123! --rdb /tmp/dump.rdb save

kubectl cp ecommerce-middleware/redis-xxx:/tmp/dump.rdb ./redis-backup.rdb

# RabbitMQ å¤‡ä»½ï¼ˆå¯¼å‡ºå®šä¹‰ï¼‰
kubectl exec -it rabbitmq-0 -n ecommerce-middleware -- \
  rabbitmqctl export_definitions /tmp/definitions.json

kubectl cp ecommerce-middleware/rabbitmq-0:/tmp/definitions.json ./rabbitmq-definitions.json
```

---

## 8. ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### 8.1 é«˜å¯ç”¨é…ç½®

```bash
# 3 ä¸ª Server èŠ‚ç‚¹ + 3 ä¸ª Agent èŠ‚ç‚¹
# Server èŠ‚ç‚¹éƒ¨ç½²
for i in 1 2 3; do
  ssh node$i "curl -sfL https://get.k3s.io | sh -s - server \
    --cluster-init \
    --tls-san=k3s-lb.prod.com \
    --disable=traefik \
    --disable=servicelb \
    --node-taint CriticalAddonsOnly=true:NoExecute"
done

# Agent èŠ‚ç‚¹éƒ¨ç½²
for i in 4 5 6; do
  ssh node$i "curl -sfL https://get.k3s.io | K3S_URL=https://k3s-lb.prod.com:6443 \
    K3S_TOKEN=xxx sh -"
done
```

### 8.2 èµ„æºé¢„ç•™

```yaml
# /etc/rancher/k3s/config.yaml
kubelet-arg:
  - "kube-reserved=cpu=500m,memory=1Gi,ephemeral-storage=1Gi"
  - "system-reserved=cpu=500m,memory=1Gi,ephemeral-storage=1Gi"
  - "eviction-hard=memory.available<500Mi,nodefs.available<10%"
```

### 8.3 å®‰å…¨åŠ å›º

```bash
# ç¦ç”¨ä¸å¿…è¦çš„ç«¯å£
firewall-cmd --permanent --add-port=6443/tcp  # API Server
firewall-cmd --permanent --add-port=10250/tcp # Kubelet
firewall-cmd --reload

# SELinux æ”¯æŒ
semanage fcontext -a -t container_runtime_exec_t /usr/local/bin/k3s
restorecon -v /usr/local/bin/k3s

# å¯ç”¨å®¡è®¡æ—¥å¿—
# /etc/rancher/k3s/config.yaml
kube-apiserver-arg:
  - "audit-log-path=/var/log/k3s-audit.log"
  - "audit-log-maxage=30"
  - "audit-log-maxbackup=10"
  - "audit-log-maxsize=100"
```

### 8.4 ç›‘æ§å‘Šè­¦

```yaml
# Prometheus AlertManager è§„åˆ™
groups:
- name: k3s-alerts
  rules:
  - alert: NodeDown
    expr: up{job="kubernetes-nodes"} == 0
    for: 5m
    annotations:
      summary: "Node {{ $labels.instance }} is down"

  - alert: HighMemoryUsage
    expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
    for: 10m
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"

  - alert: PodCrashLooping
    expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
    annotations:
      summary: "Pod {{ $labels.pod }} is crash looping"
```

### 8.5 å¤‡ä»½ç­–ç•¥

```bash
# è‡ªåŠ¨å¤‡ä»½è„šæœ¬
cat > /usr/local/bin/k3s-backup.sh <<'EOF'
#!/bin/bash
BACKUP_DIR=/backup/k3s
DATE=$(date +%Y%m%d-%H%M%S)

# etcd å¿«ç…§
k3s etcd-snapshot save --name snapshot-$DATE

# å¤‡ä»½é…ç½®
tar czf $BACKUP_DIR/config-$DATE.tar.gz \
  /etc/rancher/k3s \
  /var/lib/rancher/k3s/server/manifests

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™ 7 å¤©ï¼‰
find $BACKUP_DIR -name "*.tar.gz" -mtime +7 -delete

# ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
aws s3 cp $BACKUP_DIR/snapshot-$DATE s3://k3s-backups/
EOF

chmod +x /usr/local/bin/k3s-backup.sh

# Cron å®šæ—¶ä»»åŠ¡
echo "0 2 * * * /usr/local/bin/k3s-backup.sh" | crontab -
```

---

## 9. æ•…éšœæ’æŸ¥

### 9.1 å¸¸è§é—®é¢˜

**é—®é¢˜ 1ï¼šèŠ‚ç‚¹æ— æ³•åŠ å…¥é›†ç¾¤**
```bash
# æ£€æŸ¥é˜²ç«å¢™
sudo firewall-cmd --list-all

# æ£€æŸ¥ token
sudo cat /var/lib/rancher/k3s/server/node-token

# æŸ¥çœ‹ agent æ—¥å¿—
sudo journalctl -u k3s-agent -f
```

**é—®é¢˜ 2ï¼šPod æ— æ³•å¯åŠ¨**
```bash
# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl describe pod <pod-name>

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
kubectl logs <pod-name> -c <container-name>

# æ£€æŸ¥èŠ‚ç‚¹èµ„æº
kubectl top nodes
kubectl describe node <node-name>
```

**é—®é¢˜ 3ï¼šç½‘ç»œä¸é€š**
```bash
# æ£€æŸ¥ CNI
kubectl get pods -n kube-system -l k8s-app=flannel

# æµ‹è¯• Pod ç½‘ç»œ
kubectl run test --image=busybox --restart=Never -- sleep 3600
kubectl exec -it test -- ping <other-pod-ip>

# æ£€æŸ¥ iptables è§„åˆ™
sudo iptables-save | grep KUBE
```

### 9.2 æ€§èƒ½è°ƒä¼˜

```yaml
# /etc/rancher/k3s/config.yaml
kube-apiserver-arg:
  - "max-requests-inflight=400"
  - "max-mutating-requests-inflight=200"

kube-controller-manager-arg:
  - "node-monitor-period=5s"
  - "node-monitor-grace-period=40s"
  - "pod-eviction-timeout=30s"

kubelet-arg:
  - "max-pods=110"
  - "pods-per-core=10"
  - "serialize-image-pulls=false"
```

### 9.3 è°ƒè¯•æŠ€å·§

```bash
# è¿›å…¥èŠ‚ç‚¹è°ƒè¯•
kubectl debug node/node1 -it --image=ubuntu

# Pod è°ƒè¯•å®¹å™¨
kubectl debug pod-name -it --image=busybox --target=container-name

# ç½‘ç»œæŠ“åŒ…
kubectl sniff pod-name -c container-name

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
journalctl -xe -u k3s

# æ£€æŸ¥è¯ä¹¦
sudo openssl x509 -in /var/lib/rancher/k3s/server/tls/serving-kube-apiserver.crt -text -noout
```

### 9.4 æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# API Server å‹æµ‹
kubectl run apache-bench --image=httpd --rm -it --restart=Never -- \
  ab -n 1000 -c 10 https://kubernetes.default.svc/

# Pod å¯åŠ¨é€Ÿåº¦æµ‹è¯•
time kubectl run nginx --image=nginx --rm -it --restart=Never -- echo "done"

# å­˜å‚¨æ€§èƒ½æµ‹è¯•
kubectl apply -f - <<EOF
apiVersion: v1
kind: Pod
metadata:
  name: fio-test
spec:
  containers:
  - name: fio
    image: ljishen/fio
    command: ["fio"]
    args:
    - "--name=randwrite"
    - "--ioengine=libaio"
    - "--iodepth=32"
    - "--rw=randwrite"
    - "--bs=4k"
    - "--direct=1"
    - "--size=1G"
    - "--numjobs=1"
    - "--runtime=60"
    - "--group_reporting"
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    emptyDir: {}
EOF

kubectl logs -f fio-test
```

---

## 10. æ€»ç»“ä¸å±•æœ›

### 10.1 æ ¸å¿ƒè¦ç‚¹å›é¡¾

**K3s çš„æŠ€æœ¯ä¼˜åŠ¿ï¼š**
```
âœ… è½»é‡çº§ï¼š~70MB äºŒè¿›åˆ¶ï¼Œ512MB å†…å­˜å³å¯è¿è¡Œ
âœ… ç®€å•æ€§ï¼šå•å‘½ä»¤å®‰è£…ï¼Œé›¶ä¾èµ–
âœ… å®Œæ•´æ€§ï¼š100% Kubernetes å…¼å®¹ï¼Œé€šè¿‡ CNCF è®¤è¯
âœ… ç”Ÿäº§çº§ï¼šå†…ç½® HAã€è‡ªåŠ¨å¤‡ä»½ã€TLS åŠ å¯†
âœ… çµæ´»æ€§ï¼šæ”¯æŒ SQLite/etcd/MySQL/PostgreSQL å­˜å‚¨
```

**æœ¬æ–‡è¦†ç›–å†…å®¹ï¼š**
1. **ç†è®ºåŸºç¡€**ï¼šæ¶æ„è®¾è®¡ã€ç»„ä»¶åŸç†ã€ç²¾ç®€ç­–ç•¥
2. **å¿«é€Ÿå…¥é—¨**ï¼šå•èŠ‚ç‚¹ã€å¤šèŠ‚ç‚¹ã€é«˜å¯ç”¨éƒ¨ç½²
3. **æ ¸å¿ƒæ¦‚å¿µ**ï¼šServer/Agentã€å­˜å‚¨ã€ç½‘ç»œã€é…ç½®
4. **é«˜çº§ç‰¹æ€§**ï¼šè‡ªå®šä¹‰ CNIã€ç§æœ‰ä»“åº“ã€èµ„æºç®¡ç†
5. **ç”Ÿäº§æ¡ˆä¾‹**ï¼šå®Œæ•´å¾®æœåŠ¡ç”µå•†å¹³å°ï¼ˆ15+ ç»„ä»¶ï¼‰
6. **è¿ç»´å®è·µ**ï¼šç›‘æ§å‘Šè­¦ã€å¤‡ä»½æ¢å¤ã€æ•…éšœæ’æŸ¥

### 10.2 é€‚ç”¨åœºæ™¯å»ºè®®

| åœºæ™¯ | æ¨èåº¦ | è¯´æ˜ |
|------|--------|------|
| **è¾¹ç¼˜è®¡ç®—** | â­â­â­â­â­ | IoTã€CDN èŠ‚ç‚¹ã€åˆ†æ”¯æœºæ„ |
| **å¼€å‘æµ‹è¯•** | â­â­â­â­â­ | æœ¬åœ°å¼€å‘ã€CI/CD æµæ°´çº¿ |
| **å°å‹ç”Ÿäº§** | â­â­â­â­ | < 50 èŠ‚ç‚¹ï¼Œ< 1000 Pod |
| **å­¦ä¹ ç ”ç©¶** | â­â­â­â­â­ | Kubernetes å…¥é—¨æœ€ä½³é€‰æ‹© |
| **å¤§è§„æ¨¡é›†ç¾¤** | â­â­ | > 100 èŠ‚ç‚¹å»ºè®®ç”¨æ ‡å‡† K8s |
| **é‡‘è/æ”¿åŠ¡** | â­â­â­ | éœ€è¯„ä¼°åˆè§„æ€§è¦æ±‚ |

### 10.3 æ€§èƒ½å¯¹æ¯”ï¼ˆvs æ ‡å‡† K8sï¼‰

```
æŒ‡æ ‡å¯¹æ¯”ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     æŒ‡æ ‡        â”‚   K3s    â”‚   K8s   â”‚  æå‡   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å®‰è£…æ—¶é—´        â”‚   30s    â”‚  15min  â”‚  30x    â”‚
â”‚ å†…å­˜å ç”¨(ç©ºè½½)  â”‚  512MB   â”‚  2.5GB  â”‚  5x     â”‚
â”‚ äºŒè¿›åˆ¶å¤§å°      â”‚  70MB    â”‚  1.5GB  â”‚  20x    â”‚
â”‚ å¯åŠ¨æ—¶é—´        â”‚  10s     â”‚  60s    â”‚  6x     â”‚
â”‚ API å“åº”æ—¶é—´    â”‚  ~ç›¸åŒ   â”‚  ~ç›¸åŒ  â”‚  1x     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.4 å®æˆ˜æ¡ˆä¾‹æ€»ç»“

é€šè¿‡ç”µå•†å¹³å°æ¡ˆä¾‹ï¼Œæˆ‘ä»¬å®è·µäº†ï¼š

**æ¶æ„å±‚é¢ï¼š**
- âœ… ä¸‰å±‚æ¶æ„ï¼šå‰ç«¯ â†’ ç½‘å…³ â†’ å¾®æœåŠ¡ â†’ ä¸­é—´ä»¶
- âœ… å‘½åç©ºé—´éš”ç¦»ï¼šprod / middleware / monitoring
- âœ… æœåŠ¡å‘ç°ï¼šKubernetes Service + DNS
- âœ… æµé‡ç®¡ç†ï¼šTraefik Ingress + Middleware

**å¯é æ€§ï¼š**
- âœ… é«˜å¯ç”¨ï¼š3 èŠ‚ç‚¹ etcd é›†ç¾¤
- âœ… è‡ªæ„ˆèƒ½åŠ›ï¼šLiveness/Readiness Probe
- âœ… è‡ªåŠ¨æ‰©å®¹ï¼šHPA åŸºäº CPU/å†…å­˜
- âœ… æ»šåŠ¨æ›´æ–°ï¼šé›¶åœæœºéƒ¨ç½²

**å¯è§‚æµ‹æ€§ï¼š**
- âœ… æŒ‡æ ‡ç›‘æ§ï¼šPrometheus + Grafana
- âœ… æ—¥å¿—èšåˆï¼škubectl logsï¼ˆå¯æ‰©å±• Lokiï¼‰
- âœ… é“¾è·¯è¿½è¸ªï¼šå¯é›†æˆ Jaeger/Zipkin

**å®‰å…¨åŠ å›ºï¼š**
- âœ… ç½‘ç»œéš”ç¦»ï¼šNetworkPolicy
- âœ… å¯†é’¥ç®¡ç†ï¼šKubernetes Secret
- âœ… æƒé™æ§åˆ¶ï¼šRBAC
- âœ… TLS åŠ å¯†ï¼šé»˜è®¤å¯ç”¨

### 10.5 ä¸‹ä¸€æ­¥å­¦ä¹ è·¯å¾„

**åˆå­¦è€…ï¼ˆå·²å®Œæˆæœ¬æ–‡ï¼‰ï¼š**
```
1. æ­å»ºæœ¬åœ° K3s é›†ç¾¤
2. éƒ¨ç½²ç¤ºä¾‹åº”ç”¨
3. å­¦ä¹  kubectl å¸¸ç”¨å‘½ä»¤
4. ç†è§£ Podã€Serviceã€Deployment æ¦‚å¿µ
```

**è¿›é˜¶ï¼ˆ3-6 ä¸ªæœˆï¼‰ï¼š**
```
1. å­¦ä¹  Helm åŒ…ç®¡ç†
2. å®è·µ GitOpsï¼ˆArgoCD/Fluxï¼‰
3. é›†æˆ CI/CD æµæ°´çº¿
4. æ·±å…¥ç†è§£ç½‘ç»œå’Œå­˜å‚¨
```

**é«˜çº§ï¼ˆ6-12 ä¸ªæœˆï¼‰ï¼š**
```
1. æœåŠ¡ç½‘æ ¼ï¼ˆIstio/Linkerdï¼‰
2. å¤šé›†ç¾¤ç®¡ç†
3. è‡ªå®šä¹‰ Operator å¼€å‘
4. æ€§èƒ½è°ƒä¼˜å’Œæˆæœ¬ä¼˜åŒ–
```

### 10.6 æœªæ¥è¶‹åŠ¿

**K3s å‘å±•æ–¹å‘ï¼š**
- ğŸ”® æ›´å¥½çš„ ARM æ”¯æŒï¼ˆApple Siliconã€æ ‘è“æ´¾ï¼‰
- ğŸ”® å¢å¼ºçš„è¾¹ç¼˜è®¡ç®—èƒ½åŠ›ï¼ˆKubeEdge é›†æˆï¼‰
- ğŸ”® æ”¹è¿›çš„ HA æ–¹æ¡ˆï¼ˆKine ä¼˜åŒ–ï¼‰
- ğŸ”® WebAssembly è¿è¡Œæ—¶æ”¯æŒ

**äº‘åŸç”Ÿè¶‹åŠ¿ï¼š**
- ğŸš€ Serverless + K8sï¼ˆKnativeï¼‰
- ğŸš€ eBPF ç½‘ç»œåŠ é€Ÿï¼ˆCiliumï¼‰
- ğŸš€ GitOps æˆä¸ºæ ‡å‡†
- ğŸš€ å¹³å°å·¥ç¨‹ï¼ˆPlatform Engineeringï¼‰

### 10.7 æ¨èèµ„æº

**å®˜æ–¹æ–‡æ¡£ï¼š**
- [K3s å®˜æ–¹æ–‡æ¡£](https://docs.k3s.io/)
- [K3s GitHub](https://github.com/k3s-io/k3s)
- [SUSE Rancher](https://www.rancher.com/)

**ç¤¾åŒºèµ„æºï¼š**
- [K3s è®ºå›](https://forums.rancher.com/c/k3s/)
- [Kubernetes å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [CNCF Landscape](https://landscape.cncf.io/)

**å®æˆ˜é¡¹ç›®ï¼š**
- [Awesome K3s](https://github.com/k3s-io/awesome-k3s)
- [K3s + Raspberry Pi](https://github.com/k3s-io/k3s/discussions)
- [K3sup (K3s Setup)](https://github.com/alexellis/k3sup)

**ä¹¦ç±æ¨èï¼š**
- ã€ŠKubernetes in Actionã€‹
- ã€ŠThe Kubernetes Bookã€‹
- ã€ŠCloud Native DevOps with Kubernetesã€‹