---
title: æ·±å…¥è§£æ X (Twitter) For You æ¨èç®—æ³•ï¼šåŸºäº Grok çš„ä¸ªæ€§åŒ–å†…å®¹æ¨èç³»ç»Ÿ
published: 2026-01-26
description: å…¨æ–¹ä½å‰–æ X (Twitter) For You ä¿¡æ¯æµæ¨èç®—æ³•çš„å®Œæ•´å®ç°ï¼Œæ·±åº¦è§£æå€™é€‰éš”ç¦»æ³¨æ„åŠ›æœºåˆ¶ã€åŒå¡”æ£€ç´¢æ¶æ„ã€é›¶ç‰¹å¾å·¥ç¨‹ç­‰æ ¸å¿ƒæŠ€æœ¯ï¼ŒåŒ…å« Rust + Python + JAX æ··åˆæ¶æ„ã€Thunder å†…å­˜å¼•æ“ã€Phoenix ML æ¨¡å‹çš„è¯¦ç»†å®ç°ä¸ä¼˜åŒ–ç­–ç•¥ã€‚
tags: [æ¨èç³»ç»Ÿ, Transformer, Rust, JAX, æœºå™¨å­¦ä¹ , Grok, Twitter, æ·±åº¦å­¦ä¹ , ä¿¡æ¯æµ, æ¶æ„è®¾è®¡]
category: ç³»ç»Ÿæ¶æ„
draft: false
---

å¯¹åº”é¡¹ç›®ç½‘ç«™: https://github.com/xai-org/x-algorithm

## é¡¹ç›®æ¦‚è¿°

è¯¥é¡¹ç›®æ˜¯ä¸€ä¸ªå¼€æºçš„ Xï¼ˆåŸ Twitterï¼‰"For You" ä¿¡æ¯æµæ¨èç®—æ³•å®ç°ï¼Œå±•ç¤ºäº†ç°ä»£ç¤¾äº¤åª’ä½“å¹³å°å¦‚ä½•åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸ºæ•°äº¿ç”¨æˆ·æä¾›ä¸ªæ€§åŒ–å†…å®¹æ¨èã€‚è¯¥é¡¹ç›®ç»“åˆäº†å†…ç½‘å†…å®¹ï¼ˆä½ å…³æ³¨çš„è´¦å·ï¼‰å’Œç½‘å¤–å†…å®¹ï¼ˆé€šè¿‡æœºå™¨å­¦ä¹ å‘ç°çš„ç›¸å…³å†…å®¹ï¼‰ï¼Œä½¿ç”¨åŸºäº Grok çš„ Transformer æ¨¡å‹è¿›è¡Œç»Ÿä¸€æ’åºã€‚

**æŠ€æœ¯æ ˆ**ï¼š
- **åç«¯æœåŠ¡**ï¼šRustï¼ˆé«˜æ€§èƒ½ã€å†…å­˜å®‰å…¨ï¼‰
- **æœºå™¨å­¦ä¹ **ï¼šPython + JAXï¼ˆGoogle çš„é«˜æ€§èƒ½æ•°å€¼è®¡ç®—åº“ï¼‰
- **æ¨¡å‹æ¶æ„**ï¼šæ”¹ç¼–è‡ª xAI å¼€æºçš„ Grok-1 Transformer

## ç³»ç»Ÿæ¶æ„è®¾è®¡

### ä¸‰å¤§æ ¸å¿ƒç»„ä»¶æ·±åº¦è§£æ

#### 1. **Home Mixerï¼ˆç¼–æ’å±‚ï¼‰**

Home Mixer æ˜¯æ•´ä¸ªæ¨èç³»ç»Ÿçš„"å¤§è„‘"ï¼Œè´Ÿè´£ç¼–æ’å’Œåè°ƒæ‰€æœ‰æ¨èæµç¨‹ã€‚å®ƒé‡‡ç”¨é«˜åº¦æ¨¡å—åŒ–çš„å€™é€‰ç®¡é“ï¼ˆCandidate Pipelineï¼‰æ¡†æ¶ã€‚

##### 1.1 Query Hydratorsï¼ˆæŸ¥è¯¢æ°´åŒ–å™¨ï¼‰

**ä½œç”¨**ï¼šåœ¨æ¨èå¼€å§‹å‰ï¼Œæ”¶é›†ç”¨æˆ·çš„å®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**å®ç°çš„æ°´åŒ–å™¨**ï¼š

1. **UserActionSeqQueryHydrator**ï¼š
   - ä» UASï¼ˆUser Action Sequenceï¼‰æœåŠ¡è·å–ç”¨æˆ·æœ€è¿‘çš„äº’åŠ¨å†å²
   - åŒ…æ‹¬ï¼šç‚¹èµã€å›å¤ã€è½¬å‘ã€ç‚¹å‡»ç­‰è¡Œä¸ºåºåˆ—
   - æœ€å¤šè·å– 32 æ¡å†å²è®°å½•
   - è¿™äº›å†å²å°†ä½œä¸º Transformer çš„ä¸Šä¸‹æ–‡è¾“å…¥

2. **UserFeaturesQueryHydrator**ï¼š
   - è·å–ç”¨æˆ·çš„ç¤¾äº¤å…³ç³»ï¼ˆå…³æ³¨åˆ—è¡¨ã€ç²‰ä¸åˆ—è¡¨ï¼‰
   - è·å–ç”¨æˆ·åå¥½è®¾ç½®ï¼ˆé™éŸ³å…³é”®è¯ã€å±è”½è´¦å·ç­‰ï¼‰
   - ä» Strato åˆ†å¸ƒå¼å­˜å‚¨ä¸­è¯»å–

**å…³é”®ä¼˜åŒ–**ï¼šè¿™äº›æ°´åŒ–å™¨**å¹¶è¡Œæ‰§è¡Œ**ï¼Œå‡å°‘å»¶è¿Ÿã€‚

##### 1.2 Candidate Sourcesï¼ˆå€™é€‰æºï¼‰

**PhoenixSourceï¼ˆç½‘å¤–å†…å®¹ï¼‰**ï¼š
```rust
pub struct PhoenixSource {
    phoenix_retrieval_client: Arc<dyn PhoenixRetrievalClient>,
}
```
- è°ƒç”¨ Phoenix åŒå¡”æ£€ç´¢æ¨¡å‹
- ä»å…¨å±€è¯­æ–™åº“ä¸­å‘ç°ç›¸å…³å†…å®¹
- è¿”å› Top-1000 å€™é€‰

**ThunderSourceï¼ˆç½‘å†…å†…å®¹ï¼‰**ï¼š
```rust
pub struct ThunderSource {
    thunder_client: Arc<ThunderClient>,
}
```
- æŸ¥è¯¢ç”¨æˆ·å…³æ³¨è´¦å·çš„æœ€æ–°å¸–å­
- ç›´æ¥ä»å†…å­˜è¯»å–ï¼Œè¶…ä½å»¶è¿Ÿ
- æŒ‰å¸–å­ç±»å‹åˆ†ç±»ï¼ˆåŸåˆ›ã€è½¬å‘ã€è§†é¢‘ï¼‰

**å¹¶è¡Œç­–ç•¥**ï¼šä¸¤ä¸ªæºåŒæ—¶æŸ¥è¯¢ï¼Œç»“æœåˆå¹¶åè¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚

##### 1.3 Candidate Hydratorsï¼ˆå€™é€‰æ°´åŒ–å™¨ï¼‰

é€æ­¥ä¸°å¯Œå€™é€‰å†…å®¹çš„å…ƒæ•°æ®ï¼š

| Hydrator | åŠŸèƒ½ | æ•°æ®æº |
|----------|------|--------|
| `InNetworkCandidateHydrator` | æ ‡è®°å€™é€‰æ˜¯å¦æ¥è‡ªå…³æ³¨è´¦å· | æœ¬åœ°è®¡ç®— |
| `CoreDataCandidateHydrator` | è·å–å¸–å­æ ¸å¿ƒæ•°æ®ï¼ˆæ–‡æœ¬ã€åª’ä½“ç­‰ï¼‰ | TES (Tweet Entity Service) |
| `GizmoduckCandidateHydrator` | è·å–ä½œè€…ä¿¡æ¯ï¼ˆç”¨æˆ·åã€è®¤è¯çŠ¶æ€ï¼‰ | Gizmoduck ç”¨æˆ·æœåŠ¡ |
| `VideoDurationCandidateHydrator` | è·å–è§†é¢‘æ—¶é•¿ | TES |
| `SubscriptionHydrator` | æ£€æŸ¥ä»˜è´¹è®¢é˜…å†…å®¹è®¿é—®æƒé™ | TES |

**å…³é”®ä¼˜åŒ–**ï¼šè¿™äº›æ°´åŒ–å™¨ä¹Ÿå¯ä»¥**å¹¶è¡Œæ‰§è¡Œ**ï¼Œä½†æœ‰ä¾èµ–å…³ç³»çš„é¡ºåºæ‰§è¡Œã€‚

##### 1.4 Filtersï¼ˆè¿‡æ»¤å™¨ï¼‰

**Pre-Scoring Filters**ï¼ˆè¯„åˆ†å‰è¿‡æ»¤ï¼‰ï¼š

| ä¼˜å…ˆçº§ | Filter | è¿‡æ»¤åŸå›  | èŠ‚çœæˆæœ¬ |
|--------|--------|----------|----------|
| 1 | `DropDuplicatesFilter` | å»é™¤é‡å¤å¸–å­ ID | å‡å°‘åç»­å¤„ç† |
| 2 | `CoreDataHydrationFilter` | å»é™¤æ°´åŒ–å¤±è´¥çš„å€™é€‰ | é¿å…æ— æ•ˆæ•°æ® |
| 3 | `AgeFilter` | å»é™¤è¶…è¿‡ 24 å°æ—¶çš„æ—§å¸– | ä¿è¯æ—¶æ•ˆæ€§ |
| 4 | `SelfTweetFilter` | å»é™¤ç”¨æˆ·è‡ªå·±çš„å¸–å­ | é¿å…è‡ªæ¨è |
| 5 | `RetweetDeduplicationFilter` | å»é‡åŒä¸€å†…å®¹çš„å¤šæ¬¡è½¬å‘ | æé«˜å¤šæ ·æ€§ |
| 6 | `IneligibleSubscriptionFilter` | å»é™¤ç”¨æˆ·æ— æƒè®¿é—®çš„ä»˜è´¹å†…å®¹ | é¿å…ä»˜è´¹å¢™ |
| 7 | `PreviouslySeenPostsFilter` | å»é™¤ç”¨æˆ·å·²çœ‹è¿‡çš„å¸–å­ | å‡å°‘é‡å¤ |
| 8 | `PreviouslyServedPostsFilter` | å»é™¤æœ¬æ¬¡ä¼šè¯å·²æ¨èçš„å¸–å­ | ä¼šè¯å»é‡ |
| 9 | `MutedKeywordFilter` | å»é™¤åŒ…å«ç”¨æˆ·é™éŸ³å…³é”®è¯çš„å¸–å­ | å°Šé‡ç”¨æˆ·åå¥½ |
| 10 | `AuthorSocialgraphFilter` | å»é™¤è¢«å±è”½/é™éŸ³ä½œè€…çš„å¸–å­ | ç¤¾äº¤å›¾è°±è¿‡æ»¤ |

**å…³é”®ä¼˜åŒ–**ï¼šè¿‡æ»¤å™¨æŒ‰ç…§**ä»ä¾¿å®œåˆ°æ˜‚è´µ**çš„é¡ºåºæ‰§è¡Œï¼Œæ—©æœŸè¿‡æ»¤å¯ä»¥å¤§å¹…å‡å°‘åç»­è®¡ç®—é‡ã€‚

##### 1.5 Scorersï¼ˆè¯„åˆ†å™¨é“¾ï¼‰

é¡ºåºåº”ç”¨å¤šä¸ªè¯„åˆ†å™¨ï¼Œæ¯ä¸ªè¯„åˆ†å™¨æ·»åŠ æ–°çš„åˆ†æ•°å­—æ®µï¼š

```rust
// 1. Phoenix Scorer - ML æ¨¡å‹é¢„æµ‹
PhoenixScorer â†’ é¢„æµ‹ 14+ ç§äº’åŠ¨æ¦‚ç‡
    â†“
// 2. Weighted Scorer - åŠ æƒç»„åˆ
WeightedScorer â†’ è®¡ç®— weighted_score
    â†“
// 3. Author Diversity Scorer - å¤šæ ·æ€§è°ƒæ•´
AuthorDiversityScorer â†’ é™ä½é‡å¤ä½œè€…åˆ†æ•°
    â†“
// 4. OON Scorer - ç½‘å¤–å†…å®¹è°ƒæ•´
OONScorer â†’ è°ƒæ•´ç½‘å¤–å†…å®¹æƒé‡
```

**WeightedScorer è¯¦ç»†å®ç°**ï¼š
```rust
fn compute_weighted_score(candidate: &PostCandidate) -> f64 {
    let s = &candidate.phoenix_scores;

    // æ­£é¢ä¿¡å·ï¼ˆæ­£æƒé‡ï¼‰
    let positive_score =
        s.favorite_score * FAVORITE_WEIGHT +        // 0.5
        s.reply_score * REPLY_WEIGHT +              // 1.0
        s.retweet_score * RETWEET_WEIGHT +          // 1.0
        s.click_score * CLICK_WEIGHT +              // 0.1
        s.dwell_score * DWELL_WEIGHT +              // 0.05
        s.share_score * SHARE_WEIGHT +              // 2.0
        s.follow_author_score * FOLLOW_WEIGHT;      // 5.0

    // è´Ÿé¢ä¿¡å·ï¼ˆè´Ÿæƒé‡ï¼‰
    let negative_score =
        s.not_interested_score * NOT_INTERESTED_WEIGHT + // -10.0
        s.block_author_score * BLOCK_WEIGHT +            // -50.0
        s.mute_author_score * MUTE_WEIGHT +              // -30.0
        s.report_score * REPORT_WEIGHT;                  // -100.0

    positive_score + negative_score
}
```

**å…³é”®ä¼˜åŒ–**ï¼š
- è´Ÿé¢ä¿¡å·æƒé‡è¿œå¤§äºæ­£é¢ä¿¡å·ï¼Œå¼ºåŠ›æŠ‘åˆ¶ç”¨æˆ·å¯èƒ½è®¨åŒçš„å†…å®¹
- æ·±åº¦äº’åŠ¨ï¼ˆå›å¤ã€åˆ†äº«ã€å…³æ³¨ï¼‰æƒé‡é«˜äºæµ…åº¦äº’åŠ¨ï¼ˆç‚¹èµã€ç‚¹å‡»ï¼‰

##### 1.6 Selectorï¼ˆé€‰æ‹©å™¨ï¼‰

```rust
pub struct TopKScoreSelector;
```
- æŒ‰ `weighted_score` é™åºæ’åº
- é€‰æ‹© Top-Kï¼ˆé»˜è®¤ K=50ï¼‰

##### 1.7 Post-Selection Processingï¼ˆåé€‰æ‹©å¤„ç†ï¼‰

**VFCandidateHydrator**ï¼š
- è°ƒç”¨ Visibility Filtering æœåŠ¡
- è·å–å†…å®¹å®‰å…¨æ ‡ç­¾

**Post-Selection Filters**ï¼š

| Filter | åŠŸèƒ½ |
|--------|------|
| `VFFilter` | è¿‡æ»¤è¢«æ ‡è®°ä¸ºåƒåœ¾/æš´åŠ›/è¿è§„çš„å†…å®¹ |
| `DedupConversationFilter` | å»é‡åŒä¸€å¯¹è¯çš„å¤šä¸ªåˆ†æ”¯ |

**ä¸ºä»€ä¹ˆåç½®è¿‡æ»¤ï¼Ÿ**
- VF æœåŠ¡è°ƒç”¨æˆæœ¬é«˜ï¼Œåªå¯¹ Top-K å€™é€‰è°ƒç”¨
- é¿å…å¯¹æ‰€æœ‰å€™é€‰è¿›è¡Œæ˜‚è´µçš„å†…å®¹å®¡æ ¸

#### 2. **Thunderï¼ˆå†…å­˜å­˜å‚¨å¼•æ“ï¼‰**

Thunder æ˜¯ä¸“ä¸ºæ¨èç³»ç»Ÿè®¾è®¡çš„é«˜æ€§èƒ½å†…å­˜æ•°æ®åº“ï¼Œè§£å†³äº†ä¼ ç»Ÿæ•°æ®åº“çš„å»¶è¿Ÿé—®é¢˜ã€‚

##### 2.1 æ•°æ®ç»“æ„è®¾è®¡

```rust
pub struct PostStore {
    // å®Œæ•´å¸–å­æ•°æ®ï¼špost_id â†’ LightPost
    posts: Arc<DashMap<i64, LightPost>>,

    // æŒ‰ç”¨æˆ·ç´¢å¼•çš„åŸåˆ›å¸–å­ï¼šuser_id â†’ [TinyPost]
    original_posts_by_user: Arc<DashMap<i64, VecDeque<TinyPost>>>,

    // æŒ‰ç”¨æˆ·ç´¢å¼•çš„å›å¤/è½¬å‘ï¼šuser_id â†’ [TinyPost]
    secondary_posts_by_user: Arc<DashMap<i64, VecDeque<TinyPost>>>,

    // æŒ‰ç”¨æˆ·ç´¢å¼•çš„è§†é¢‘å¸–å­ï¼šuser_id â†’ [TinyPost]
    video_posts_by_user: Arc<DashMap<i64, VecDeque<TinyPost>>>,

    // å·²åˆ é™¤å¸–å­æ ‡è®°
    deleted_posts: Arc<DashMap<i64, bool>>,

    retention_seconds: u64,
    request_timeout: Duration,
}
```

**TinyPost vs LightPost**ï¼š
- `TinyPost`ï¼šä»…å­˜å‚¨ `(post_id, created_at)`ï¼Œæå°å†…å­˜å ç”¨
- `LightPost`ï¼šå­˜å‚¨å®Œæ•´å¸–å­å…ƒæ•°æ®ï¼ˆæ–‡æœ¬ã€åª’ä½“ã€ä½œè€… ID ç­‰ï¼‰

**è®¾è®¡ä¼˜åŠ¿**ï¼š
- ç”¨æˆ·ç´¢å¼•åªå­˜å‚¨ TinyPost å¼•ç”¨ï¼ŒèŠ‚çœå†…å­˜
- å®é™…æ•°æ®åœ¨ `posts` è¡¨ä¸­ï¼Œé¿å…é‡å¤å­˜å‚¨
- ä½¿ç”¨ `VecDeque` å®ç°é«˜æ•ˆçš„ FIFO é˜Ÿåˆ—

##### 2.2 å®æ—¶æ•°æ®æ‘„å–

```rust
// Kafka æ¶ˆè´¹è€…ç›‘å¬å¸–å­äº‹ä»¶
pub struct TweetEventsListener {
    kafka_consumer: StreamConsumer,
    post_store: Arc<PostStore>,
}

impl TweetEventsListener {
    async fn consume_events(&self) {
        loop {
            match self.kafka_consumer.recv().await {
                Ok(message) => {
                    let event = parse_tweet_event(message);
                    match event {
                        TweetEvent::Create(post) => {
                            self.post_store.add_post(post);
                        }
                        TweetEvent::Delete(post_id) => {
                            self.post_store.mark_as_deleted(post_id);
                        }
                    }
                }
                Err(e) => log::error!("Kafka error: {}", e),
            }
        }
    }
}
```

**å…³é”®ç‰¹æ€§**ï¼š
- æ¯«ç§’çº§å»¶è¿Ÿï¼šä»å¸–å­å‘å¸ƒåˆ°å¯è¢«æ£€ç´¢ < 100ms
- è‡ªåŠ¨åˆ†ç±»ï¼šæ ¹æ®å¸–å­ç±»å‹è‡ªåŠ¨æ”¾å…¥ä¸åŒç´¢å¼•
- å®¹é”™è®¾è®¡ï¼šKafka æ¶ˆè´¹å¤±è´¥ä¸å½±å“æŸ¥è¯¢æœåŠ¡

##### 2.3 æŸ¥è¯¢æ¥å£

```rust
impl PostStore {
    /// è·å–æŒ‡å®šç”¨æˆ·åˆ—è¡¨çš„æœ€æ–°å¸–å­
    pub fn get_posts_by_users(
        &self,
        user_ids: &[i64],
        max_posts_per_user: usize,
    ) -> Vec<LightPost> {
        let start = Instant::now();
        let mut results = Vec::new();

        for user_id in user_ids {
            // æ£€æŸ¥è¶…æ—¶
            if self.request_timeout > 0 && start.elapsed() > self.request_timeout {
                break;
            }

            // ä»åŸåˆ›å¸–å­ç´¢å¼•è·å–
            if let Some(posts) = self.original_posts_by_user.get(user_id) {
                for tiny_post in posts.iter().take(max_posts_per_user) {
                    if let Some(full_post) = self.posts.get(&tiny_post.post_id) {
                        results.push(full_post.clone());
                    }
                }
            }
        }

        results
    }
}
```

**æ€§èƒ½ç‰¹å¾**ï¼š
- P50 å»¶è¿Ÿï¼š< 1ms
- P99 å»¶è¿Ÿï¼š< 5ms
- ååé‡ï¼š100K+ QPSï¼ˆå•æœºï¼‰

##### 2.4 å†…å­˜ç®¡ç†

**è‡ªåŠ¨æ¸…ç†æœºåˆ¶**ï¼š
```rust
async fn cleanup_old_posts(&self) {
    let now = SystemTime::now();
    let cutoff = now - Duration::from_secs(self.retention_seconds);

    // éå†æ‰€æœ‰å¸–å­ï¼Œåˆ é™¤è¿‡æœŸæ•°æ®
    self.posts.retain(|_, post| {
        post.created_at > cutoff
    });

    // æ¸…ç†ç”¨æˆ·ç´¢å¼•ä¸­çš„è¿‡æœŸå¼•ç”¨
    for mut entry in self.original_posts_by_user.iter_mut() {
        entry.retain(|tiny| tiny.created_at > cutoff);
    }
}
```

**å†…å­˜å ç”¨ä¼°ç®—**ï¼š
- 1 äº¿æ¡å¸–å­ï¼ˆ24 å°æ—¶ï¼‰
- æ¯æ¡ LightPost â‰ˆ 200 bytes
- æ¯æ¡ TinyPost â‰ˆ 16 bytes
- æ€»å†…å­˜ â‰ˆ 20GB - 30GBï¼ˆå¯å•æœºéƒ¨ç½²ï¼‰

#### 3. **Phoenixï¼ˆæœºå™¨å­¦ä¹ æ ¸å¿ƒï¼‰**

Phoenix æ˜¯æ¨èç³»ç»Ÿçš„æ™ºèƒ½å¼•æ“ï¼ŒåŒ…å«æ£€ç´¢å’Œæ’åºä¸¤ä¸ªæ¨¡å‹ã€‚

##### 3.1 æ£€ç´¢æ¨¡å‹ - åŒå¡”æ¶æ„

**ä¸ºä»€ä¹ˆéœ€è¦åŒå¡”ï¼Ÿ**
- å€™é€‰æ•°é‡ï¼šæ•°åƒä¸‡ - æ•°äº¿æ¡å¸–å­
- å»¶è¿Ÿè¦æ±‚ï¼š< 50ms
- ä¼ ç»Ÿ Transformerï¼šO(N) å¤æ‚åº¦ï¼Œæ— æ³•å®æ—¶è®¡ç®—

**åŒå¡”è§£å†³æ–¹æ¡ˆ**ï¼š
```
ç¦»çº¿é˜¶æ®µï¼š
    å€™é€‰å¡”ï¼ˆCandidate Towerï¼‰å¯¹æ‰€æœ‰å¸–å­è¿›è¡Œç¼–ç 
    â†’ ç”Ÿæˆå¸–å­å‘é‡åº“ [N, D]
    â†’ å­˜å…¥å‘é‡æ•°æ®åº“ï¼ˆå¦‚ FAISSã€ScaNNï¼‰

åœ¨çº¿é˜¶æ®µï¼š
    ç”¨æˆ·å¡”ï¼ˆUser Towerï¼‰å¯¹å½“å‰ç”¨æˆ·ç¼–ç 
    â†’ ç”Ÿæˆç”¨æˆ·å‘é‡ [1, D]
    â†’ ä¸å‘é‡åº“è¿›è¡Œ ANN æœç´¢
    â†’ è¿”å› Top-1000 æœ€ç›¸ä¼¼å¸–å­
```

**ç”¨æˆ·å¡”æ¶æ„**ï¼š
```python
class UserTower(hk.Module):
    def __call__(self, user_features, user_history):
        # 1. ç”¨æˆ·ç‰¹å¾åµŒå…¥
        user_emb = self.user_embedding(user_features)  # [B, D]

        # 2. å†å²åºåˆ—ç¼–ç 
        history_embs = self.post_embedding(user_history)  # [B, S, D]

        # 3. Transformer ç¼–ç 
        transformer_out = self.transformer(
            jnp.concatenate([user_emb, history_embs], axis=1)
        )  # [B, S+1, D]

        # 4. æ± åŒ–ä¸ºå•ä¸€å‘é‡
        user_vector = transformer_out[:, 0, :]  # å– CLS token

        # 5. L2 å½’ä¸€åŒ–
        user_vector = user_vector / jnp.linalg.norm(user_vector, axis=-1, keepdims=True)

        return user_vector  # [B, D]
```

**å€™é€‰å¡”æ¶æ„**ï¼š
```python
class CandidateTower(hk.Module):
    def __call__(self, post_features):
        # 1. å¸–å­å†…å®¹åµŒå…¥
        post_emb = self.post_embedding(post_features)  # [N, D]

        # 2. ä½œè€…ä¿¡æ¯åµŒå…¥
        author_emb = self.author_embedding(post_features.author_id)  # [N, D]

        # 3. ç»„åˆåµŒå…¥
        combined = post_emb + author_emb

        # 4. MLP æŠ•å½±
        candidate_vector = self.mlp(combined)  # [N, D]

        # 5. L2 å½’ä¸€åŒ–
        candidate_vector = candidate_vector / jnp.linalg.norm(
            candidate_vector, axis=-1, keepdims=True
        )

        return candidate_vector  # [N, D]
```

**ç›¸ä¼¼åº¦è®¡ç®—**ï¼š
```python
# ç”¨æˆ·å‘é‡ï¼š[B, D]
# å€™é€‰å‘é‡ï¼š[N, D]
scores = jnp.dot(user_vector, candidate_vectors.T)  # [B, N]

# Top-K æ£€ç´¢
top_k_indices = jnp.argsort(scores, axis=-1)[:, -1000:]  # [B, 1000]
```

**è®­ç»ƒç›®æ ‡**ï¼š
- æ­£æ ·æœ¬ï¼šç”¨æˆ·å®é™…äº’åŠ¨è¿‡çš„å¸–å­
- è´Ÿæ ·æœ¬ï¼šéšæœºé‡‡æ · + æ‰¹å†…è´Ÿé‡‡æ ·
- æŸå¤±å‡½æ•°ï¼šSoftmax Cross-Entropy

##### 3.2 æ’åºæ¨¡å‹ - Transformer with Candidate Isolation

**æ¨¡å‹è¾“å…¥**ï¼š
```python
class RecsysBatch:
    # ç”¨æˆ·ç‰¹å¾
    user_hashes: [B, num_user_hashes]

    # å†å²åºåˆ—ï¼ˆæœ€å¤š 32 æ¡ï¼‰
    history_post_hashes: [B, S, num_item_hashes]
    history_author_hashes: [B, S, num_author_hashes]
    history_actions: [B, S]              # ç”¨æˆ·åœ¨å†å²å¸–å­ä¸Šçš„è¡Œä¸º
    history_product_surface: [B, S]      # äº§å“ç•Œé¢ï¼ˆTimeline/Search/Notificationï¼‰

    # å€™é€‰åºåˆ—ï¼ˆ8-16 æ¡ï¼‰
    candidate_post_hashes: [B, C, num_item_hashes]
    candidate_author_hashes: [B, C, num_author_hashes]
    candidate_product_surface: [B, C]
```

**å“ˆå¸ŒåµŒå…¥æŸ¥æ‰¾**ï¼š
```python
def hash_embedding_lookup(hashes, embedding_table, num_hashes):
    """
    hashes: [B, num_hashes]  ä¾‹å¦‚ [[123, 456], [789, 012]]
    embedding_table: [vocab_size, D]
    """
    # æŸ¥æ‰¾æ¯ä¸ªå“ˆå¸Œå€¼çš„åµŒå…¥
    embeddings = embedding_table[hashes]  # [B, num_hashes, D]

    # æ‹¼æ¥å¤šä¸ªå“ˆå¸ŒåµŒå…¥
    concatenated = embeddings.reshape(B, num_hashes * D)

    # æŠ•å½±å›åŸå§‹ç»´åº¦
    combined = jnp.dot(concatenated, projection_matrix)  # [B, D]

    return combined
```

**ä¸ºä»€ä¹ˆä½¿ç”¨å¤šå“ˆå¸Œï¼Ÿ**
- **å‡å°‘å†²çª**ï¼šå•å“ˆå¸Œå‡½æ•°å®¹æ˜“ç¢°æ’ï¼Œå¤šå“ˆå¸Œé™ä½å†²çªæ¦‚ç‡
- **å¢å¼ºè¡¨è¾¾**ï¼šä¸åŒå“ˆå¸Œå‡½æ•°æ•è·ä¸åŒç‰¹å¾
- **å¤„ç†é•¿å°¾**ï¼šç½•è§è¯æ±‡ä¹Ÿèƒ½å¾—åˆ°åˆç†è¡¨ç¤º

**Transformer å‰å‘ä¼ æ’­**ï¼š
```python
def forward(batch, embeddings):
    # 1. åµŒå…¥å±‚
    user_emb = block_user_reduce(batch.user_hashes, embeddings.user_embeddings)
    history_embs = block_history_reduce(
        batch.history_post_hashes,
        embeddings.history_post_embeddings,
        embeddings.history_author_embeddings,
        batch.history_actions,
        batch.history_product_surface,
    )
    candidate_embs = block_candidate_reduce(
        batch.candidate_post_hashes,
        embeddings.candidate_post_embeddings,
        embeddings.candidate_author_embeddings,
        batch.candidate_product_surface,
    )

    # 2. æ‹¼æ¥è¾“å…¥åºåˆ—
    #    [User | History_1 ... History_S | Candidate_1 ... Candidate_C]
    input_seq = jnp.concatenate([user_emb, history_embs, candidate_embs], axis=1)

    # 3. åˆ›å»ºå€™é€‰éš”ç¦»æ³¨æ„åŠ›æ©ç 
    attn_mask = make_recsys_attn_mask(
        seq_len=1 + S + C,
        candidate_start_offset=1 + S,
    )

    # 4. Transformer ç¼–ç 
    transformer_out = transformer(input_seq, attn_mask)

    # 5. æå–å€™é€‰è¾“å‡º
    candidate_outputs = transformer_out[:, 1+S:, :]  # [B, C, D]

    # 6. å¤šä»»åŠ¡é¢„æµ‹å¤´
    logits = prediction_head(candidate_outputs)  # [B, C, num_actions]

    return logits
```

**è¾“å‡ºæ ¼å¼**ï¼š
```python
logits: [B, C, num_actions]
# B = batch_size
# C = num_candidates
# num_actions = 14ï¼ˆfavorite, reply, repost, ...ï¼‰

# è½¬æ¢ä¸ºæ¦‚ç‡
probs = jax.nn.sigmoid(logits)  # [B, C, 14]
```

## æ ¸å¿ƒæŠ€æœ¯äº®ç‚¹æ·±åº¦è§£æ

### ğŸŒŸ äº®ç‚¹ 1ï¼šå€™é€‰éš”ç¦»æ³¨æ„åŠ›æœºåˆ¶ï¼ˆCandidate Isolationï¼‰

#### é—®é¢˜èƒŒæ™¯

åœ¨ä¼ ç»Ÿ Transformer æ¨èæ¨¡å‹ä¸­ï¼Œæ‰€æœ‰å€™é€‰å†…å®¹åœ¨åŒä¸€æ‰¹æ¬¡ä¸­è¿›è¡Œå¤„ç†ï¼š

```
è¾“å…¥åºåˆ—ï¼š[User, History_1, ..., History_32, Cand_1, Cand_2, ..., Cand_8]
                                                    â†‘          â†‘
                                                    |          |
                                       è¿™äº›å€™é€‰å¯ä»¥äº’ç›¸å…³æ³¨ï¼ˆFull Attentionï¼‰
```

**é—®é¢˜**ï¼š
1. **æ‰¹æ¬¡ä¾èµ–**ï¼šCand_1 çš„åˆ†æ•°ä¼šå—åˆ° Cand_2, Cand_3 ç­‰çš„å½±å“
2. **ä¸ä¸€è‡´æ€§**ï¼šåŒä¸€æ¡å¸–å­åœ¨ä¸åŒæ‰¹æ¬¡ä¸­å¯èƒ½å¾—åˆ°ä¸åŒåˆ†æ•°
3. **æ— æ³•ç¼“å­˜**ï¼šç”±äºæ‰¹æ¬¡ä¾èµ–ï¼Œå€™é€‰åˆ†æ•°æ— æ³•é¢„è®¡ç®—ç¼“å­˜

#### Phoenix çš„è§£å†³æ–¹æ¡ˆ

```python
def make_recsys_attn_mask(seq_len, candidate_start_offset):
    """åˆ›å»ºæ¨èç³»ç»Ÿä¸“ç”¨çš„æ³¨æ„åŠ›æ©ç """
    # 1. ä»å› æœæ©ç å¼€å§‹ï¼ˆä¸‹ä¸‰è§’çŸ©é˜µï¼‰
    causal_mask = jnp.tril(jnp.ones((1, 1, seq_len, seq_len)))

    # 2. å°†å€™é€‰åŒºåŸŸçš„éå¯¹è§’çº¿å…ƒç´ ç½® 0ï¼ˆç¦æ­¢å€™é€‰é—´äº’ç›¸å…³æ³¨ï¼‰
    attn_mask = causal_mask.at[:, :, candidate_start_offset:,
                                candidate_start_offset:].set(0)

    # 3. æ¢å¤å€™é€‰çš„è‡ªæ³¨æ„åŠ›ï¼ˆå¯¹è§’çº¿å…ƒç´ ï¼‰
    candidate_indices = jnp.arange(candidate_start_offset, seq_len)
    attn_mask = attn_mask.at[:, :, candidate_indices, candidate_indices].set(1)

    return attn_mask
```

**æ³¨æ„åŠ›æ©ç å¯è§†åŒ–**ï¼š
```
        Keys (what we attend TO)
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
        â”‚ U â”‚  History  â”‚   Candidates   â”‚
    â”Œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  Q â”‚ U â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ— âœ— âœ— âœ—   â”‚
  u â”‚ H â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ— âœ— âœ— âœ—   â”‚
  e â”‚ i â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ— âœ— âœ— âœ—   â”‚
  r â”‚ s â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ— âœ— âœ— âœ—   â”‚
  i â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  e â”‚ C â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ“ âœ— âœ— âœ— âœ— âœ—   â”‚ â† Cand_1 åªèƒ½çœ‹è‡ªå·±
  s â”‚ a â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ“ âœ— âœ— âœ— âœ—   â”‚ â† Cand_2 åªèƒ½çœ‹è‡ªå·±
    â”‚ n â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ“ âœ— âœ— âœ—   â”‚ â† Cand_3 åªèƒ½çœ‹è‡ªå·±
    â”‚ d â”‚ âœ“ â”‚  âœ“ âœ“ âœ“ âœ“  â”‚  âœ— âœ— âœ— âœ“ âœ— âœ—   â”‚
    â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### å¸¦æ¥çš„ä¼˜åŠ¿

1. **è¯„åˆ†ä¸€è‡´æ€§**ï¼š
   ```python
   # åŒä¸€æ¡å¸–å­åœ¨ä¸åŒæ‰¹æ¬¡ä¸­å¾—åˆ°ç›¸åŒåˆ†æ•°
   batch_1 = [user, history, post_A, post_B, post_C]
   batch_2 = [user, history, post_A, post_X, post_Y]

   # post_A åœ¨ä¸¤ä¸ªæ‰¹æ¬¡ä¸­çš„åˆ†æ•°å®Œå…¨ä¸€è‡´
   score(post_A | batch_1) == score(post_A | batch_2)
   ```

2. **åˆ†æ•°ç¼“å­˜**ï¼š
   ```python
   # å¯ä»¥é¢„å…ˆè®¡ç®—çƒ­é—¨å¸–å­çš„åˆ†æ•°
   cache_key = hash(user_id, user_history, post_id)
   if cache_key in cache:
       return cache[cache_key]
   else:
       score = model.predict(user, history, post)
       cache[cache_key] = score
       return score
   ```

3. **å¹¶è¡Œæ¨ç†**ï¼š
   ```python
   # å¯ä»¥å°†å€™é€‰åˆ†ç‰‡ï¼Œå¹¶è¡Œæ¨ç†
   candidates = [post_1, post_2, ..., post_1000]

   # åˆ†æˆ 10 æ‰¹ï¼Œæ¯æ‰¹ 100 ä¸ªå€™é€‰
   batches = chunk(candidates, 100)

   # å¹¶è¡Œè®¡ç®—ï¼ˆæ¯æ‰¹ç‹¬ç«‹ï¼‰
   scores = parallel_map(lambda batch: model.predict(user, history, batch), batches)
   ```

4. **A/B æµ‹è¯•å‹å¥½**ï¼š
   - å€™é€‰åˆ†æ•°ç‹¬ç«‹ï¼Œæ–¹ä¾¿è¿›è¡Œå¯¹ç…§å®éªŒ
   - å¯ä»¥ç²¾ç¡®æµ‹é‡å•ä¸ªå€™é€‰çš„æ•ˆæœ

#### ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”

| ç»´åº¦ | ä¼ ç»Ÿ Full Attention | Candidate Isolation |
|------|---------------------|---------------------|
| è¯„åˆ†ä¸€è‡´æ€§ | âŒ æ‰¹æ¬¡ç›¸å…³ | âœ… æ‰¹æ¬¡æ— å…³ |
| ç¼“å­˜èƒ½åŠ› | âŒ æ— æ³•ç¼“å­˜ | âœ… å¯ç¼“å­˜ |
| å¹¶è¡Œæ¨ç† | âŒ å¿…é¡»æ•´æ‰¹ | âœ… å¯åˆ†ç‰‡ |
| æ¨¡å‹è¡¨è¾¾åŠ› | é«˜ï¼ˆå€™é€‰é—´äº¤äº’ï¼‰ | ä¸­ï¼ˆæ— å€™é€‰é—´äº¤äº’ï¼‰ |
| è®­ç»ƒå¤æ‚åº¦ | é«˜ | ä½ |

**æƒè¡¡**ï¼šè™½ç„¶å€™é€‰éš”ç¦»é™ä½äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼ˆå€™é€‰æ— æ³•äº’ç›¸å‚è€ƒï¼‰ï¼Œä½†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œ**ä¸€è‡´æ€§å’Œå¯ç¼“å­˜æ€§** è¿œæ¯”å¾®å°çš„æ¨¡å‹æ€§èƒ½æå‡æ›´é‡è¦ã€‚

### ğŸŒŸ äº®ç‚¹ 2ï¼šé›¶æ‰‹å·¥ç‰¹å¾å·¥ç¨‹

#### ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„ç‰¹å¾å·¥ç¨‹å™©æ¢¦

ä¼ ç»Ÿæ¨èç³»ç»Ÿéœ€è¦è®¾è®¡æ•°ç™¾ä¸ªæ‰‹å·¥ç‰¹å¾ï¼š

```python
# ä¼ ç»Ÿç‰¹å¾ç¤ºä¾‹
features = {
    # å†…å®¹ç‰¹å¾
    'post_age_hours': (now - post.created_at).hours,
    'post_length': len(post.text),
    'has_image': int(post.has_image),
    'has_video': int(post.has_video),
    'num_hashtags': len(post.hashtags),
    'num_mentions': len(post.mentions),

    # ä½œè€…ç‰¹å¾
    'author_follower_count': author.follower_count,
    'author_verified': int(author.verified),
    'author_creation_date': (now - author.created_at).days,
    'author_post_frequency': author.posts_last_30d / 30,

    # äº’åŠ¨ç‰¹å¾
    'post_like_count': post.like_count,
    'post_retweet_count': post.retweet_count,
    'post_reply_count': post.reply_count,
    'engagement_rate': post.engagements / post.impressions,

    # ç”¨æˆ·-å†…å®¹åŒ¹é…ç‰¹å¾
    'user_author_similarity': cosine_similarity(user.interests, author.topics),
    'topic_match_score': compute_topic_match(user.history, post.topics),
    'language_match': int(user.language == post.language),

    # ... 100+ æ›´å¤šç‰¹å¾
}
```

**é—®é¢˜**ï¼š
- ğŸ”¥ **ç»´æŠ¤æˆæœ¬é«˜**ï¼šæ¯ä¸ªç‰¹å¾éœ€è¦ä¸“é—¨çš„æ•°æ®ç®¡é“
- ğŸ”¥ **é¢†åŸŸçŸ¥è¯†ä¾èµ–**ï¼šéœ€è¦æ·±å…¥ç†è§£ä¸šåŠ¡æ‰èƒ½è®¾è®¡å¥½ç‰¹å¾
- ğŸ”¥ **æ‰©å±•å›°éš¾**ï¼šæ–°å¢ç‰¹å¾éœ€è¦æ”¹é€ æ•´ä¸ªç³»ç»Ÿ
- ğŸ”¥ **æ—¶æ•ˆæ€§å·®**ï¼šç‰¹å¾è®¡ç®—å¯èƒ½æœ‰å»¶è¿Ÿï¼ˆå¦‚ follower_countï¼‰

#### Phoenix çš„ç«¯åˆ°ç«¯å­¦ä¹ 

```python
# Phoenix åªéœ€è¦åŸå§‹ ID å’Œè¡Œä¸ºåºåˆ—
inputs = {
    'user_id': user_id,
    'history_post_ids': [post_1, post_2, ..., post_32],
    'history_actions': [like, retweet, reply, ...],
    'candidate_post_ids': [cand_1, cand_2, ..., cand_8],
}

# æ¨¡å‹è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤º
predictions = model.predict(inputs)
```

**æ¨¡å‹å¦‚ä½•å­¦ä¹ éšå¼ç‰¹å¾ï¼Ÿ**

1. **åµŒå…¥å±‚æ•è·å®ä½“ç‰¹å¾**ï¼š
   ```python
   # å¸–å­åµŒå…¥è‡ªåŠ¨ç¼–ç äº†ï¼šè¯é¢˜ã€é£æ ¼ã€è´¨é‡ç­‰
   post_embedding = embedding_table[post_id]  # å­¦ä¹ åˆ°çš„ 128 ç»´å‘é‡

   # ç¤ºä¾‹ï¼šç›¸ä¼¼è¯é¢˜çš„å¸–å­åµŒå…¥æ¥è¿‘
   sports_post_1: [0.8, 0.1, -0.3, ...]
   sports_post_2: [0.7, 0.2, -0.2, ...]
   politics_post: [-0.5, 0.9, 0.4, ...]
   ```

2. **Transformer æ•è·åºåˆ—æ¨¡å¼**ï¼š
   ```python
   # è‡ªåŠ¨å­¦ä¹ ç”¨æˆ·çš„å…´è¶£æ¼”å˜
   history = [post_1, post_2, post_3, ...]

   # Transformer å‘ç°æ¨¡å¼ï¼š
   # - ç”¨æˆ·æœ€è¿‘å¯¹ç§‘æŠ€è¯é¢˜æ„Ÿå…´è¶£
   # - ç”¨æˆ·å€¾å‘äºåœ¨æ—©æ™¨é˜…è¯»æ–°é—»
   # - ç”¨æˆ·å–œæ¬¢æœ‰å›¾ç‰‡çš„é•¿æ–‡
   ```

3. **å¤šä»»åŠ¡å­¦ä¹ æ•è·è¡Œä¸ºåå¥½**ï¼š
   ```python
   # åŒæ—¶é¢„æµ‹å¤šä¸ªè¡Œä¸ºï¼Œæ¨¡å‹å­¦åˆ°ä¸åŒè¡Œä¸ºçš„ç‰¹å¾
   outputs = {
       'P(like)': 0.8,      # ç”¨æˆ·å¯èƒ½ç‚¹èµï¼ˆè¡¨ç¤ºæµ…å±‚å…´è¶£ï¼‰
       'P(reply)': 0.2,     # ç”¨æˆ·ä¸å¤ªä¼šå›å¤ï¼ˆå†…å®¹ä¸å¤Ÿå¼•äººè®¨è®ºï¼‰
       'P(share)': 0.1,     # ç”¨æˆ·ä¸å¤ªä¼šåˆ†äº«ï¼ˆå†…å®¹ä¸å¤Ÿä¼˜è´¨ï¼‰
   }
   # æ¨¡å‹è‡ªåŠ¨åŒºåˆ†äº†"å®¹æ˜“ç‚¹èµ"å’Œ"å€¼å¾—åˆ†äº«"çš„å†…å®¹
   ```

#### å¯¹æ¯”å®éªŒç»“æœ

æ ¹æ® README ä¸­çš„æè¿°ï¼š

> "We have eliminated every single hand-engineered feature and most heuristics from the system."

**å¸¦æ¥çš„å¥½å¤„**ï¼š
- âœ… **æ•°æ®ç®¡é“ç®€åŒ–**ï¼šåªéœ€ ID æµå’Œè¡Œä¸ºæ—¥å¿—
- âœ… **å»¶è¿Ÿé™ä½**ï¼šæ— éœ€ç­‰å¾…ç‰¹å¾è®¡ç®—
- âœ… **æ›´å¼ºæ³›åŒ–**ï¼šæ¨¡å‹è‡ªåŠ¨å‘ç°ç‰¹å¾ï¼Œä¸å—äººç±»è®¤çŸ¥åè§é™åˆ¶
- âœ… **å¿«é€Ÿè¿­ä»£**ï¼šæ–°ä¸šåŠ¡åœºæ™¯æ— éœ€é‡æ–°è®¾è®¡ç‰¹å¾

### ğŸŒŸ äº®ç‚¹ 3ï¼šå¤šåŠ¨ä½œé¢„æµ‹ï¼ˆMulti-Task Learningï¼‰

#### ä¸ºä»€ä¹ˆä¸èƒ½åªé¢„æµ‹"ç›¸å…³æ€§"ï¼Ÿ

å•ä¸€ç›¸å…³æ€§åˆ†æ•°çš„é—®é¢˜ï¼š
```python
# ä¼ ç»Ÿå•ç›®æ ‡æ¨¡å‹
relevance_score = model.predict(user, post)  # åªæœ‰ä¸€ä¸ªæ•°å­—

# é—®é¢˜ï¼šæ— æ³•åŒºåˆ†ä¸åŒç±»å‹çš„ç›¸å…³æ€§
post_A: relevance = 0.8  # ç”¨æˆ·ä¼šçœ‹ï¼Œä½†å¯èƒ½ä¸å–œæ¬¢
post_B: relevance = 0.7  # ç”¨æˆ·ä¸ä»…ä¼šçœ‹ï¼Œè¿˜ä¼šåˆ†äº«
```

#### Phoenix çš„å¤šä»»åŠ¡å­¦ä¹ æ¶æ„

```python
class PhoenixModel:
    def __call__(self, user, history, candidates):
        # å…±äº« Transformer ç¼–ç å™¨
        embeddings = self.transformer(user, history, candidates)

        # 14 ä¸ªç‹¬ç«‹çš„é¢„æµ‹å¤´
        predictions = {
            # æ­£é¢ä¿¡å·
            'P(favorite)': sigmoid(self.favorite_head(embeddings)),
            'P(reply)': sigmoid(self.reply_head(embeddings)),
            'P(repost)': sigmoid(self.repost_head(embeddings)),
            'P(quote)': sigmoid(self.quote_head(embeddings)),
            'P(click)': sigmoid(self.click_head(embeddings)),
            'P(profile_click)': sigmoid(self.profile_click_head(embeddings)),
            'P(video_view)': sigmoid(self.video_view_head(embeddings)),
            'P(photo_expand)': sigmoid(self.photo_expand_head(embeddings)),
            'P(share)': sigmoid(self.share_head(embeddings)),
            'P(dwell_2s+)': sigmoid(self.dwell_head(embeddings)),
            'P(follow_author)': sigmoid(self.follow_head(embeddings)),

            # è´Ÿé¢ä¿¡å·
            'P(not_interested)': sigmoid(self.not_interested_head(embeddings)),
            'P(block_author)': sigmoid(self.block_head(embeddings)),
            'P(mute_author)': sigmoid(self.mute_head(embeddings)),
            'P(report)': sigmoid(self.report_head(embeddings)),
        }
        return predictions
```

#### åŠ æƒç»„åˆç­–ç•¥

```rust
fn compute_weighted_score(phoenix_scores: &PhoenixScores) -> f64 {
    // æ­£é¢ä¿¡å·ï¼ˆæ­£æƒé‡ï¼‰
    let positive =
        phoenix_scores.favorite_score * 0.5 +
        phoenix_scores.reply_score * 1.0 +        // æ·±åº¦äº’åŠ¨æƒé‡æ›´é«˜
        phoenix_scores.repost_score * 1.0 +
        phoenix_scores.quote_score * 0.8 +
        phoenix_scores.click_score * 0.1 +        // æµ…å±‚äº’åŠ¨æƒé‡è¾ƒä½
        phoenix_scores.share_score * 2.0 +        // åˆ†äº«æ˜¯å¼ºä¿¡å·
        phoenix_scores.follow_author_score * 5.0; // å…³æ³¨ä½œè€…æ˜¯æœ€å¼ºä¿¡å·

    // è´Ÿé¢ä¿¡å·ï¼ˆè´Ÿæƒé‡ï¼Œç»å¯¹å€¼å¾ˆå¤§ï¼‰
    let negative =
        phoenix_scores.not_interested_score * -10.0 +
        phoenix_scores.block_author_score * -50.0 +
        phoenix_scores.mute_author_score * -30.0 +
        phoenix_scores.report_score * -100.0;     // ä¸¾æŠ¥æ˜¯æœ€å¼ºè´Ÿä¿¡å·

    positive + negative
}
```

**æƒé‡è®¾è®¡å“²å­¦**ï¼š
- æ·±åº¦äº’åŠ¨ï¼ˆreply, share, followï¼‰> æµ…å±‚äº’åŠ¨ï¼ˆlike, clickï¼‰
- è´Ÿé¢ä¿¡å·æƒé‡è¿œå¤§äºæ­£é¢ä¿¡å·ï¼ˆå®å¯å°‘æ¨èï¼Œä¸è¦æ¨èé”™ï¼‰
- æƒé‡å¯ä»¥é€šè¿‡çº¿ä¸Š A/B æµ‹è¯•åŠ¨æ€è°ƒæ•´

#### å¤šä»»åŠ¡å­¦ä¹ çš„ä¼˜åŠ¿

1. **æ›´ä¸°å¯Œçš„ç”¨æˆ·ç†è§£**ï¼š
   ```python
   # ç¤ºä¾‹ï¼šä¸¤ä¸ªç›¸ä¼¼çš„å¸–å­
   post_A:
       P(like) = 0.9    # ç”¨æˆ·å¾ˆå¯èƒ½ç‚¹èµ
       P(reply) = 0.1   # ä½†ä¸å¤ªä¼šå›å¤
       â†’ æµ…å±‚å…´è¶£ï¼Œå¨±ä¹å†…å®¹

   post_B:
       P(like) = 0.6    # ç”¨æˆ·å¯èƒ½ç‚¹èµ
       P(reply) = 0.7   # å¾ˆå¯èƒ½å›å¤
       P(share) = 0.5   # å¯èƒ½åˆ†äº«
       â†’ æ·±åº¦å…´è¶£ï¼Œé«˜è´¨é‡å†…å®¹

   # æœ€ç»ˆåˆ†æ•°ï¼špost_B > post_A
   ```

2. **è´Ÿé¢ä¿¡å·è¿‡æ»¤**ï¼š
   ```python
   post_C:
       P(like) = 0.8
       P(block) = 0.3   # æœ‰ 30% æ¦‚ç‡è¢«å±è”½
       â†’ æœ€ç»ˆåˆ†æ•° = 0.8 * 0.5 + 0.3 * (-50) = -14.6ï¼ˆä¸æ¨èï¼‰
   ```

3. **è®­ç»ƒä¿¡å·ä¸°å¯Œ**ï¼š
   ```python
   # ä¼ ç»Ÿå•ä»»åŠ¡ï¼šåªæœ‰ç‚¹å‡»/æœªç‚¹å‡»ä¸¤ç§æ ‡ç­¾
   labels = [1, 0, 1, 0, ...]  # ä¿¡å·ç¨€ç–

   # å¤šä»»åŠ¡ï¼š14 ç§è¡Œä¸ºéƒ½æ˜¯è®­ç»ƒä¿¡å·
   labels = {
       'like': [1, 0, 1, 0, ...],
       'reply': [0, 0, 1, 0, ...],
       'share': [0, 0, 0, 0, ...],
       ...
   }
   # å³ä½¿ç”¨æˆ·æ²¡æœ‰ç‚¹èµï¼Œ"reply" å’Œ "share" ä¹Ÿæä¾›äº†è®­ç»ƒä¿¡å·
   ```

### ğŸŒŸ äº®ç‚¹ 4ï¼šå¯ç»„åˆçš„ç®¡é“æ¶æ„

#### è®¾è®¡æ¨¡å¼ï¼šè´£ä»»é“¾ + ä¾èµ–æ³¨å…¥

```rust
pub trait CandidatePipeline<Q, C> {
    // å®šä¹‰ç®¡é“çš„å„ä¸ªé˜¶æ®µ
    fn query_hydrators(&self) -> &[Box<dyn QueryHydrator<Q>>];
    fn sources(&self) -> &[Box<dyn Source<Q, C>>];
    fn hydrators(&self) -> &[Box<dyn Hydrator<Q, C>>];
    fn filters(&self) -> &[Box<dyn Filter<Q, C>>];
    fn scorers(&self) -> &[Box<dyn Scorer<Q, C>>];
    fn selector(&self) -> &dyn Selector<Q, C>;

    // æ‰§è¡Œç®¡é“çš„æ¨¡æ¿æ–¹æ³•
    async fn execute(&self, query: Q) -> PipelineResult<Q, C> {
        let query = self.hydrate_query(query).await;
        let candidates = self.fetch_candidates(&query).await;
        let candidates = self.hydrate(&query, candidates).await;
        let candidates = self.filter(&query, candidates).await;
        let candidates = self.score(&query, candidates).await;
        let candidates = self.select(&query, candidates);
        PipelineResult { candidates, query }
    }
}
```

#### å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–

```rust
async fn hydrate_query(&self, mut query: Q) -> Q {
    // æ‰€æœ‰ query hydrators å¹¶è¡Œæ‰§è¡Œ
    let hydrators = self.query_hydrators();
    let futures: Vec<_> = hydrators
        .iter()
        .map(|h| h.hydrate(&query))
        .collect();

    let results = join_all(futures).await;

    // åˆå¹¶ç»“æœåˆ° query
    for result in results {
        query.merge(result);
    }
    query
}

async fn fetch_candidates(&self, query: &Q) -> Vec<C> {
    // æ‰€æœ‰ sources å¹¶è¡ŒæŸ¥è¯¢
    let sources = self.sources();
    let futures: Vec<_> = sources
        .iter()
        .map(|s| s.fetch(query))
        .collect();

    let results = join_all(futures).await;

    // åˆå¹¶æ‰€æœ‰å€™é€‰
    results.into_iter().flatten().collect()
}
```

**æ€§èƒ½æå‡**ï¼š
- ä¸²è¡Œæ‰§è¡Œï¼š100ms (query hydration) + 50ms (sources) = 150ms
- å¹¶è¡Œæ‰§è¡Œï¼šmax(100ms, 50ms) = 100ms
- **å»¶è¿Ÿé™ä½ 33%**

#### æ˜“æ‰©å±•æ€§ç¤ºä¾‹

**æ·»åŠ æ–°æ•°æ®æº**ï¼š
```rust
pub struct TrendingSource {
    trending_service: Arc<TrendingService>,
}

#[async_trait]
impl Source<ScoredPostsQuery, PostCandidate> for TrendingSource {
    async fn fetch(&self, query: &ScoredPostsQuery) -> Vec<PostCandidate> {
        let trending_posts = self.trending_service
            .get_trending_posts(query.user_location)
            .await?;

        trending_posts.into_iter()
            .map(|p| PostCandidate::from_trending(p))
            .collect()
    }
}

// åœ¨ pipeline ä¸­æ³¨å†Œï¼ˆæ— éœ€ä¿®æ”¹æ¡†æ¶ä»£ç ï¼‰
let sources = vec![
    Box::new(ThunderSource { ... }),
    Box::new(PhoenixSource { ... }),
    Box::new(TrendingSource { ... }),  // æ–°å¢æ•°æ®æº
];
```

**æ·»åŠ æ–°è¿‡æ»¤å™¨**ï¼š
```rust
pub struct LanguageFilter {
    supported_languages: HashSet<String>,
}

#[async_trait]
impl Filter<ScoredPostsQuery, PostCandidate> for LanguageFilter {
    async fn filter(
        &self,
        query: &ScoredPostsQuery,
        candidates: &[PostCandidate],
    ) -> Result<Vec<bool>, String> {
        let keep_flags = candidates
            .iter()
            .map(|c| {
                c.language
                    .as_ref()
                    .map(|lang| self.supported_languages.contains(lang))
                    .unwrap_or(false)
            })
            .collect();
        Ok(keep_flags)
    }
}

// åœ¨ pipeline ä¸­æ³¨å†Œ
filters.push(Box::new(LanguageFilter { ... }));
```

#### é”™è¯¯å¤„ç†ç­–ç•¥

```rust
async fn fetch_candidates(&self, query: &Q) -> Vec<C> {
    let sources = self.sources();
    let futures: Vec<_> = sources.iter().map(|s| s.fetch(query)).collect();
    let results = join_all(futures).await;

    let mut all_candidates = Vec::new();
    for (idx, result) in results.into_iter().enumerate() {
        match result {
            Ok(candidates) => {
                all_candidates.extend(candidates);
            }
            Err(e) => {
                // å•ä¸ªæºå¤±è´¥ä¸å½±å“æ•´ä½“
                log::warn!("Source {} failed: {}", idx, e);
                emit_metric("source_failure", &[("source_id", idx.to_string())]);
            }
        }
    }
    all_candidates
}
```

**ä¼˜é›…é™çº§**ï¼šå³ä½¿æŸä¸ªæ•°æ®æºå¤±è´¥ï¼Œç³»ç»Ÿä»èƒ½è¿”å›å…¶ä»–æºçš„ç»“æœã€‚

### ğŸŒŸ äº®ç‚¹ 5ï¼šåŸºäºå“ˆå¸Œçš„åµŒå…¥æŸ¥æ‰¾ï¼ˆHash Embeddingsï¼‰

#### ä¼ ç»ŸåµŒå…¥è¡¨çš„é—®é¢˜

```python
# ä¼ ç»ŸåµŒå…¥è¡¨
vocab_size = 100_000_000  # 1 äº¿ä¸ªå¸–å­
embedding_dim = 128

embedding_table = np.zeros((vocab_size, embedding_dim))
# å†…å­˜å ç”¨ï¼š100M * 128 * 4 bytes = 51.2 GBï¼ˆå•ä¸ªè¡¨ï¼‰
```

**é—®é¢˜**ï¼š
- ğŸ”¥ **å†…å­˜çˆ†ç‚¸**ï¼šID ç©ºé—´å·¨å¤§ï¼ˆæ•°äº¿å¸–å­ Ã— æ•°äº¿ç”¨æˆ·ï¼‰
- ğŸ”¥ **é•¿å°¾ç¨€ç–**ï¼šå¤§éƒ¨åˆ† ID å¾ˆå°‘å‡ºç°ï¼ŒåµŒå…¥å¾—ä¸åˆ°å……åˆ†è®­ç»ƒ
- ğŸ”¥ **æ— æ³•æ³›åŒ–**ï¼šæ–° ID æ²¡æœ‰åµŒå…¥å‘é‡ï¼ˆå†·å¯åŠ¨ï¼‰

#### Hash Embedding è§£å†³æ–¹æ¡ˆ

```python
class HashEmbedding(hk.Module):
    def __init__(self, num_hashes=4, hash_vocab_size=1_000_000, emb_dim=128):
        self.num_hashes = num_hashes
        self.hash_vocab_size = hash_vocab_size
        self.emb_dim = emb_dim

        # åˆ›å»ºå¤šä¸ªå°çš„åµŒå…¥è¡¨
        self.embedding_tables = [
            hk.get_parameter(
                f"hash_embedding_{i}",
                shape=[hash_vocab_size, emb_dim],
                init=hk.initializers.TruncatedNormal(stddev=0.01),
            )
            for i in range(num_hashes)
        ]

    def __call__(self, ids):
        """
        ids: [B, S] åŸå§‹ IDï¼ˆå¯ä»¥éå¸¸å¤§ï¼‰
        returns: [B, S, emb_dim]
        """
        embeddings = []
        for i, embedding_table in enumerate(self.embedding_tables):
            # ä½¿ç”¨ä¸åŒçš„å“ˆå¸Œå‡½æ•°
            hashed_ids = hash_function(ids, seed=i) % self.hash_vocab_size
            emb = embedding_table[hashed_ids]  # [B, S, emb_dim]
            embeddings.append(emb)

        # ç»„åˆå¤šä¸ªå“ˆå¸ŒåµŒå…¥
        combined = sum(embeddings) / self.num_hashes
        return combined
```

**å†…å­˜å¯¹æ¯”**ï¼š
```python
# ä¼ ç»Ÿæ–¹æ³•
memory_traditional = 100_000_000 * 128 * 4 = 51.2 GB

# Hash Embeddingï¼ˆ4 ä¸ªå“ˆå¸Œè¡¨ï¼‰
memory_hash = 4 * 1_000_000 * 128 * 4 = 2.05 GB

# èŠ‚çœ 96% å†…å­˜ï¼
```

#### å¤šå“ˆå¸Œå‡½æ•°çš„ä¼˜åŠ¿

**1. é™ä½å†²çªæ¦‚ç‡**ï¼š
```python
# å•å“ˆå¸Œï¼šä¸¤ä¸ªä¸åŒ ID å¯èƒ½å†²çª
hash(post_123, seed=0) % 1M = 456789
hash(post_456, seed=0) % 1M = 456789  # å†²çªï¼

# å¤šå“ˆå¸Œï¼šå†²çªæ¦‚ç‡æŒ‡æ•°ä¸‹é™
P(collision with 1 hash) = 1 / 1M
P(collision with 4 hashes) = (1 / 1M) ^ 4 â‰ˆ 0
```

**2. æ›´ä¸°å¯Œçš„è¡¨ç¤º**ï¼š
```python
# æ¯ä¸ªå“ˆå¸Œå‡½æ•°æ•è·ä¸åŒæ–¹é¢
hash_0(post_id) â†’ æ•è·è¯é¢˜ç‰¹å¾
hash_1(post_id) â†’ æ•è·ä½œè€…ç‰¹å¾
hash_2(post_id) â†’ æ•è·æ—¶é—´ç‰¹å¾
hash_3(post_id) â†’ æ•è·æ ¼å¼ç‰¹å¾

# ç»„åˆåå¾—åˆ°å…¨é¢çš„è¡¨ç¤º
final_embedding = (emb_0 + emb_1 + emb_2 + emb_3) / 4
```

**3. å¤©ç„¶å¤„ç†å†·å¯åŠ¨**ï¼š
```python
# æ–°å¸–å­ï¼ˆä»æœªè§è¿‡çš„ IDï¼‰
new_post_id = 999_999_999

# ä»ç„¶å¯ä»¥è·å¾—åˆç†çš„åµŒå…¥ï¼ˆåŸºäºå“ˆå¸Œå€¼ï¼‰
embedding = hash_embedding(new_post_id)

# å³ä½¿æ˜¯å…¨æ–°çš„ IDï¼Œç”±äºå“ˆå¸Œå‡½æ•°çš„å‡åŒ€æ€§ï¼Œ
# å®ƒä¼šæ˜ å°„åˆ°å·²è®­ç»ƒçš„åµŒå…¥ç©ºé—´ä¸­çš„æŸä¸ªä½ç½®
```

#### Phoenix ä¸­çš„å®é™…åº”ç”¨

```python
class RecsysModel:
    def __init__(self, config):
        # ç”¨æˆ· Hash Embeddingï¼ˆ2 ä¸ªå“ˆå¸Œï¼‰
        self.user_embedding = HashEmbedding(
            num_hashes=config.num_user_hashes,  # 2
            hash_vocab_size=10_000_000,
            emb_dim=config.emb_size,
        )

        # å¸–å­ Hash Embeddingï¼ˆ2 ä¸ªå“ˆå¸Œï¼‰
        self.post_embedding = HashEmbedding(
            num_hashes=config.num_item_hashes,  # 2
            hash_vocab_size=50_000_000,
            emb_dim=config.emb_size,
        )

        # ä½œè€… Hash Embeddingï¼ˆ2 ä¸ªå“ˆå¸Œï¼‰
        self.author_embedding = HashEmbedding(
            num_hashes=config.num_author_hashes,  # 2
            hash_vocab_size=10_000_000,
            emb_dim=config.emb_size,
        )
```

**æ€»å†…å­˜å ç”¨**ï¼š
```
ç”¨æˆ·è¡¨ï¼š2 * 10M * 128 * 4 bytes = 10 GB
å¸–å­è¡¨ï¼š2 * 50M * 128 * 4 bytes = 50 GB
ä½œè€…è¡¨ï¼š2 * 10M * 128 * 4 bytes = 10 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ€»è®¡ï¼š70 GBï¼ˆå¯åœ¨å• GPU ä¸Šè®­ç»ƒï¼‰
```

ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ˆæ•°ç™¾ GBï¼‰ï¼ŒèŠ‚çœäº† **70-80% å†…å­˜**ã€‚

## é¡¹ç›®çš„æ ¸å¿ƒä¼˜åŒ–ç‚¹

### 1. å»¶è¿Ÿä¼˜åŒ–

#### 1.1 å¹¶è¡Œæ‰§è¡Œ
```rust
// æ‰€æœ‰ç‹¬ç«‹é˜¶æ®µå¹¶è¡Œæ‰§è¡Œ
async fn execute_pipeline(&self, query: Q) {
    // å¹¶è¡ŒæŸ¥è¯¢æ°´åŒ–
    let hydrators = self.query_hydrators();
    let hydration_futures = hydrators.iter().map(|h| h.hydrate(&query));
    let hydrated_query = join_all(hydration_futures).await;

    // å¹¶è¡Œå€™é€‰æºæŸ¥è¯¢
    let sources = self.sources();
    let source_futures = sources.iter().map(|s| s.fetch(&hydrated_query));
    let candidates = join_all(source_futures).await;
}
```

**æ”¶ç›Š**ï¼š
- ä¸²è¡Œï¼š150ms â†’ å¹¶è¡Œï¼š60ms
- **P99 å»¶è¿Ÿé™ä½ 60%**

#### 1.2 æ—©æœŸè¿‡æ»¤
```rust
// è¿‡æ»¤å™¨æŒ‰æˆæœ¬ä»ä½åˆ°é«˜æ’åº
let filters = vec![
    DropDuplicatesFilter,        // æˆæœ¬ï¼šO(N)ï¼Œå†…å­˜æ“ä½œ
    AgeFilter,                    // æˆæœ¬ï¼šO(N)ï¼Œç®€å•æ¯”è¾ƒ
    SelfTweetFilter,              // æˆæœ¬ï¼šO(N)ï¼ŒIDæ¯”è¾ƒ
    AuthorSocialgraphFilter,      // æˆæœ¬ï¼šO(N*M)ï¼Œç¤¾äº¤å›¾è°±æŸ¥è¯¢
    MutedKeywordFilter,           // æˆæœ¬ï¼šO(N*K)ï¼Œæ–‡æœ¬åŒ¹é…
    VFFilter,                     // æˆæœ¬ï¼šO(N)ï¼ŒRPCè°ƒç”¨ï¼ˆæœ€è´µï¼‰
];

// æ—©æœŸè¿‡æ»¤å‡å°‘åç»­å¤„ç†é‡
candidates: 1000 â†’ 800 (DropDuplicates)
         â†’ 600 (AgeFilter)
         â†’ 550 (SelfTweetFilter)
         â†’ 500 (AuthorSocialgraph)
         â†’ 450 (MutedKeyword)
         â†’ 400 (VFFilterï¼Œåªå¤„ç† 400 ä¸ªï¼Œè€Œä¸æ˜¯ 1000 ä¸ª)
```

**æ”¶ç›Š**ï¼šå‡å°‘ 60% çš„æ˜‚è´µ RPC è°ƒç”¨

#### 1.3 Thunder å†…å­˜å­˜å‚¨
```rust
// ä¼ ç»Ÿæ–¹æ³•ï¼šæŸ¥è¯¢æ•°æ®åº“
let posts = database.query("SELECT * FROM posts WHERE author_id IN (?)", following_ids).await;
// å»¶è¿Ÿï¼š20-50msï¼ˆP99ï¼‰

// Thunderï¼šå†…å­˜æŸ¥è¯¢
let posts = thunder_store.get_posts_by_users(&following_ids);
// å»¶è¿Ÿï¼š< 1msï¼ˆP99ï¼‰

// å»¶è¿Ÿé™ä½ 95%+
```

### 2. ååé‡ä¼˜åŒ–

#### 2.1 æ‰¹å¤„ç†æ¨ç†
```python
# å•æ¡æ¨ç†ï¼šä½æ•ˆ
for post in candidates:
    score = model.predict(user, history, post)

# æ‰¹é‡æ¨ç†ï¼šé«˜æ•ˆï¼ˆGPU åˆ©ç”¨ç‡æ›´é«˜ï¼‰
batch_size = 32
for i in range(0, len(candidates), batch_size):
    batch = candidates[i:i+batch_size]
    scores = model.predict_batch(user, history, batch)

# ååé‡æå‡ï¼š32x
```

#### 2.2 æ¨¡å‹é‡åŒ–
```python
# FP32 æ¨¡å‹ï¼š4 bytes per parameter
model_fp32_size = 1B params * 4 bytes = 4 GB
inference_speed = 100 QPS

# INT8 é‡åŒ–ï¼š1 byte per parameter
model_int8_size = 1B params * 1 byte = 1 GB
inference_speed = 300 QPS

# é€Ÿåº¦æå‡ 3xï¼Œå†…å­˜å‡å°‘ 75%
```

### 3. æˆæœ¬ä¼˜åŒ–

#### 3.1 åˆ†æ•°ç¼“å­˜
```python
# ç¼“å­˜çƒ­é—¨å¸–å­çš„åˆ†æ•°
cache = LRUCache(size=1_000_000)

def get_score(user_id, user_history_hash, post_id):
    cache_key = (user_id, user_history_hash, post_id)

    if cache_key in cache:
        return cache[cache_key]  # ç¼“å­˜å‘½ä¸­

    score = model.predict(user, history, post)
    cache[cache_key] = score
    return score

# ç¼“å­˜å‘½ä¸­ç‡ï¼š30-40%
# è®¡ç®—æˆæœ¬é™ä½ï¼š30-40%
```

#### 3.2 æ¨¡å‹å‹ç¼©
```python
# Hash Embedding å‹ç¼©
traditional_embedding_size = 100M * 128 * 4 = 50 GB
hash_embedding_size = 4 * 10M * 128 * 4 = 20 GB

# å­˜å‚¨æˆæœ¬é™ä½ 60%
# è®­ç»ƒæˆæœ¬é™ä½ 50%ï¼ˆæ›´å°‘çš„å‚æ•°æ›´æ–°ï¼‰
```

### 4. å¯é æ€§ä¼˜åŒ–

#### 4.1 ä¼˜é›…é™çº§
```rust
async fn fetch_candidates(&self, query: &Q) -> Vec<C> {
    let mut candidates = Vec::new();

    // Thunder æºå¤±è´¥ â†’ åªç”¨ Phoenix æº
    match thunder_source.fetch(query).await {
        Ok(thunder_candidates) => candidates.extend(thunder_candidates),
        Err(e) => {
            log::warn!("Thunder source failed, falling back to Phoenix only");
            emit_metric("thunder_failure");
        }
    }

    // Phoenix æºå¤±è´¥ â†’ åªç”¨ Thunder æº
    match phoenix_source.fetch(query).await {
        Ok(phoenix_candidates) => candidates.extend(phoenix_candidates),
        Err(e) => {
            log::warn!("Phoenix source failed, using Thunder only");
            emit_metric("phoenix_failure");
        }
    }

    candidates
}

// å•ä¸ªæºå¤±è´¥ä¸å½±å“æ•´ä½“æœåŠ¡
// å¯ç”¨æ€§ä» 99% â†’ 99.99%
```

#### 4.2 è¶…æ—¶ä¿æŠ¤
```rust
// Thunder æŸ¥è¯¢å¸¦è¶…æ—¶
pub fn get_posts_by_users(
    &self,
    user_ids: &[i64],
    timeout: Duration,
) -> Vec<LightPost> {
    let start = Instant::now();

    for user_id in user_ids {
        if start.elapsed() > timeout {
            log::warn!("Query timeout, returning partial results");
            break;  // è¿”å›éƒ¨åˆ†ç»“æœï¼Œè€Œä¸æ˜¯å¤±è´¥
        }
        // ... æŸ¥è¯¢é€»è¾‘
    }
}

// é¿å…æ…¢æŸ¥è¯¢æ‹–å®æ•´ä¸ªç³»ç»Ÿ
```

### 5. å¼€å‘æ•ˆç‡ä¼˜åŒ–

#### 5.1 æ¨¡å—åŒ–è®¾è®¡
```rust
// æ·»åŠ æ–°åŠŸèƒ½æ— éœ€ä¿®æ”¹æ ¸å¿ƒä»£ç 
impl NewFeatureFilter { ... }
filters.push(Box::new(NewFeatureFilter));

// å¼€å‘å‘¨æœŸï¼šæ•°å‘¨ â†’ æ•°å¤©
```

#### 5.2 å¯è§‚æµ‹æ€§
```rust
#[xai_stats_macro::receive_stats]
async fn score(&self, query: &Q, candidates: &[C]) {
    // è‡ªåŠ¨è®°å½•ï¼š
    // - å»¶è¿Ÿï¼ˆP50, P99ï¼‰
    // - æˆåŠŸç‡
    // - å€™é€‰æ•°é‡åˆ†å¸ƒ
}

// é—®é¢˜æ’æŸ¥æ—¶é—´ï¼šæ•°å°æ—¶ â†’ æ•°åˆ†é’Ÿ
```

## å®Œæ•´çš„æ¨èæµç¨‹

```
ç”¨æˆ·è¯·æ±‚
    â†“
[1. æŸ¥è¯¢æ°´åŒ–] è·å–ç”¨æˆ·äº’åŠ¨å†å²ã€å…³æ³¨åˆ—è¡¨ç­‰
    â†“
[2. å€™é€‰æ£€ç´¢]
    â”œâ”€ Thunder: å…³æ³¨è´¦å·çš„æœ€æ–°å¸–å­ï¼ˆç½‘å†…å†…å®¹ï¼‰
    â””â”€ Phoenix Retrieval: MLå‘ç°çš„ç›¸å…³å¸–å­ï¼ˆç½‘å¤–å†…å®¹ï¼‰
    â†“
[3. å†…å®¹æ°´åŒ–] è¡¥å……å¸–å­å…ƒæ•°æ®ã€ä½œè€…ä¿¡æ¯ã€åª’ä½“ä¿¡æ¯
    â†“
[4. é¢„è¯„åˆ†è¿‡æ»¤] ç§»é™¤ï¼šé‡å¤ã€è¿‡æ—§ã€è‡ªå·±çš„ã€å·²å±è”½ã€å·²é™éŸ³ç­‰
    â†“
[5. ML è¯„åˆ†]
    â”œâ”€ Phoenix Scorer: Transformer é¢„æµ‹äº’åŠ¨æ¦‚ç‡
    â”œâ”€ Weighted Scorer: ç»„åˆå¤šä¸ªé¢„æµ‹
    â”œâ”€ Author Diversity: é™ä½åŒä¸€ä½œè€…é‡å¤å‡ºç°
    â””â”€ OON Scorer: è°ƒæ•´ç½‘å¤–å†…å®¹åˆ†æ•°
    â†“
[6. é€‰æ‹©] æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹© Top-K
    â†“
[7. åé€‰æ‹©è¿‡æ»¤] å†…å®¹å®¡æ ¸ï¼ˆåƒåœ¾ã€æš´åŠ›ã€è¿è§„ç­‰ï¼‰
    â†“
ä¸ªæ€§åŒ–æ¨èæµ
```

## å®ç°ç»†èŠ‚

### è¿‡æ»¤å™¨ç³»ç»Ÿ
é¡¹ç›®å®ç°äº† 12+ ç§è¿‡æ»¤å™¨ï¼Œç¡®ä¿å†…å®¹è´¨é‡ï¼š

| è¿‡æ»¤å™¨ | ä½œç”¨ |
|--------|------|
| `DropDuplicatesFilter` | å»é‡ |
| `AgeFilter` | è¿‡æ»¤è¿‡æ—§å†…å®¹ |
| `SelfTweetFilter` | ç§»é™¤ç”¨æˆ·è‡ªå·±çš„å¸–å­ |
| `AuthorSocialgraphFilter` | ç§»é™¤å·²å±è”½/é™éŸ³ä½œè€… |
| `MutedKeywordFilter` | ç§»é™¤åŒ…å«é™éŸ³å…³é”®è¯çš„å†…å®¹ |
| `PreviouslySeenPostsFilter` | ç§»é™¤å·²çœ‹è¿‡çš„å†…å®¹ |
| `VFFilter` | å†…å®¹å®¡æ ¸ï¼ˆåƒåœ¾ã€æš´åŠ›ç­‰ï¼‰ |

### è¯„åˆ†å™¨é“¾
é¡ºåºåº”ç”¨å¤šä¸ªè¯„åˆ†å™¨ï¼š
1. **Phoenix Scorer**ï¼šè·å– ML æ¨¡å‹é¢„æµ‹
2. **Weighted Scorer**ï¼šç»„åˆæˆæœ€ç»ˆç›¸å…³æ€§åˆ†æ•°
3. **Author Diversity Scorer**ï¼šç¡®ä¿ä¿¡æ¯æµå¤šæ ·æ€§
4. **OON Scorer**ï¼šè°ƒæ•´ç½‘å¤–å†…å®¹æƒé‡

## æŠ€æœ¯é€‰å‹çš„æ™ºæ…§

1. **Rust for æœåŠ¡å±‚**ï¼šå†…å­˜å®‰å…¨ã€é«˜æ€§èƒ½ã€å¹¶å‘å‹å¥½
2. **JAX for ML**ï¼šJIT ç¼–è¯‘ã€è‡ªåŠ¨å¾®åˆ†ã€GPU/TPU åŠ é€Ÿ
3. **Grok-1 æ¶æ„**ï¼šç»è¿‡éªŒè¯çš„å¤§è§„æ¨¡ Transformer æ¶æ„
4. **å†…å­˜å­˜å‚¨ï¼ˆThunderï¼‰**ï¼šäºšæ¯«ç§’çº§å“åº”ï¼Œæ— éœ€æ•°æ®åº“æŸ¥è¯¢
5. **å¼‚æ­¥ç®¡é“**ï¼šå¹¶è¡Œæ‰§è¡Œç‹¬ç«‹é˜¶æ®µï¼Œæœ€å¤§åŒ–ååé‡

## ä¸šåŠ¡åœºæ™¯ä¸åº”ç”¨

### å…¸å‹ä¸šåŠ¡åœºæ™¯

#### 1. ç¤¾äº¤åª’ä½“ä¿¡æ¯æµæ¨è
**åœºæ™¯æè¿°**ï¼šä¸º Twitter/X è¿™æ ·çš„ç¤¾äº¤åª’ä½“å¹³å°æä¾›ä¸ªæ€§åŒ– "For You" ä¿¡æ¯æµã€‚

**ä¸šåŠ¡éœ€æ±‚**ï¼š
- æ¯å¤©ä¸ºæ•°äº¿ç”¨æˆ·ç”Ÿæˆä¸ªæ€§åŒ–æ¨è
- å¹³è¡¡å…³æ³¨è´¦å·ï¼ˆIn-Networkï¼‰å’Œæ–°å‘ç°å†…å®¹ï¼ˆOut-of-Networkï¼‰
- å®æ—¶å“åº”ï¼ˆP99 å»¶è¿Ÿ < 200msï¼‰
- é«˜åº¦ä¸ªæ€§åŒ–ï¼ˆåŸºäºæ¯ä¸ªç”¨æˆ·çš„ç‹¬ç‰¹äº’åŠ¨å†å²ï¼‰

**ç³»ç»Ÿè§£å†³æ–¹æ¡ˆ**ï¼š
```
ç”¨æˆ·åˆ·æ–°ä¿¡æ¯æµ
    â†’ Home Mixer æ¥æ”¶è¯·æ±‚
    â†’ Thunder æä¾›å…³æ³¨è´¦å·çš„æœ€æ–°å¸–å­ï¼ˆç½‘å†…ï¼‰
    â†’ Phoenix Retrieval å‘ç°ç›¸å…³å¸–å­ï¼ˆç½‘å¤–ï¼‰
    â†’ Phoenix Ranker ç»Ÿä¸€æ’åºæ‰€æœ‰å€™é€‰
    â†’ è¿”å›ä¸ªæ€§åŒ–æ’åºç»“æœ
```

#### 2. å†…å®¹å†·å¯åŠ¨é—®é¢˜
**åœºæ™¯æè¿°**ï¼šæ–°ç”¨æˆ·æˆ–æ–°å‘å¸ƒçš„å¸–å­å¦‚ä½•è·å¾—æ›å…‰ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **æ–°ç”¨æˆ·å†·å¯åŠ¨**ï¼šé€šè¿‡åŒå¡”æ£€ç´¢æ¨¡å‹ï¼Œå³ä½¿ç”¨æˆ·å†å²å¾ˆå°‘ï¼Œä¹Ÿèƒ½åŸºäºåŸºæœ¬ç‰¹å¾ï¼ˆå¦‚å…³æ³¨åˆ—è¡¨ï¼‰æ‰¾åˆ°ç›¸å…³å†…å®¹
- **æ–°å¸–å­å†·å¯åŠ¨**ï¼šThunder å®æ—¶æ‘„å–æ–°å¸–å­ï¼Œç»“åˆä½œè€…çš„å†å²è¡¨ç°å’Œå†…å®¹ç‰¹å¾è¿›è¡Œåˆå§‹è¯„åˆ†

#### 3. å¤šæ ·æ€§ä¸ç›¸å…³æ€§å¹³è¡¡
**åœºæ™¯æè¿°**ï¼šé¿å…ä¿¡æ¯æµè¢«å•ä¸€ä½œè€…æˆ–è¯é¢˜ä¸»å¯¼ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **Author Diversity Scorer**ï¼šé™ä½åŒä¸€ä½œè€…é‡å¤å‡ºç°çš„å¸–å­åˆ†æ•°
- **OON Scorer**ï¼šè°ƒæ•´ç½‘å¤–å†…å®¹æƒé‡ï¼Œç¡®ä¿æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡
- **å¤šåŠ¨ä½œé¢„æµ‹**ï¼šä¸ä»…å…³æ³¨ç‚¹èµï¼Œè¿˜è€ƒè™‘å›å¤ã€åˆ†äº«ç­‰æ·±åº¦äº’åŠ¨

#### 4. å†…å®¹å®‰å…¨ä¸åˆè§„
**åœºæ™¯æè¿°**ï¼šè¿‡æ»¤åƒåœ¾ä¿¡æ¯ã€æš´åŠ›å†…å®¹ã€è¿è§„å†…å®¹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
- **Pre-Scoring Filters**ï¼šæ—©æœŸè¿‡æ»¤æ˜æ˜¾è¿è§„å†…å®¹ï¼ŒèŠ‚çœè®¡ç®—èµ„æº
- **VF Filter (Visibility Filtering)**ï¼šåç½®è¿‡æ»¤ï¼Œä½¿ç”¨ä¸“é—¨çš„å†…å®¹å®¡æ ¸æœåŠ¡
- **è´Ÿé¢ä¿¡å·é¢„æµ‹**ï¼šæ¨¡å‹é¢„æµ‹ P(block)ã€P(report) ç­‰è´Ÿé¢è¡Œä¸ºï¼Œä¸»åŠ¨é™æƒ

### é€‚ç”¨çš„å…¶ä»–ä¸šåŠ¡åœºæ™¯

1. **ç”µå•†æ¨è**ï¼šå•†å“æ¨èã€ä¸ªæ€§åŒ–é¦–é¡µ
2. **è§†é¢‘å¹³å°**ï¼šçŸ­è§†é¢‘æ¨èã€ç›´æ’­æ¨è
3. **æ–°é—»èšåˆ**ï¼šä¸ªæ€§åŒ–æ–°é—»æ¨è
4. **éŸ³ä¹æµåª’ä½“**ï¼šæ­Œæ›²ã€æ’­æ”¾åˆ—è¡¨æ¨è
5. **å¹¿å‘ŠæŠ•æ”¾**ï¼šç²¾å‡†å¹¿å‘ŠåŒ¹é…

## å¦‚ä½•ä½¿ç”¨

### å¿«é€Ÿå¯åŠ¨

#### ç¯å¢ƒå‡†å¤‡
```bash
# 1. å®‰è£… uvï¼ˆç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼‰
pip install uv

# æˆ–ä½¿ç”¨ curl å®‰è£…
curl -LsSf https://astral.sh/uv/install.sh | sh
```

#### è¿è¡Œæ’åºæ¨¡å‹ï¼ˆRankerï¼‰

```bash
cd phoenix
uv run run_ranker.py
```

**è¿è¡Œç¤ºä¾‹è¾“å‡º**ï¼š
```
======================================================================
RECOMMENDATION SYSTEM DEMO
======================================================================

User has viewed 32 posts in their history
Ranking 8 candidate posts...

----------------------------------------------------------------------
RANKING RESULTS (ordered by predicted 'Favorite Score' probability)
----------------------------------------------------------------------

Rank 1:
  Predicted engagement probabilities:
    Favorite Score          : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 0.823
    Reply Score             : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.312
    Repost Score            : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.421
    Quote Score             : â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.156
    Click Score             : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 0.712
    Profile Click Score     : â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.089
    Video View Score        : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.634
    Photo Expand Score      : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.467
    Share Score             : â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.201
    Dwell Score             : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.578
    Follow Author Score     : â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.034
    Not Interested Score    : â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.012
    Block Author Score      : â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.003
    Mute Author Score       : â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.005
    Report Score            : â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.001

Rank 2:
  ...

======================================================================
Demo complete!
======================================================================
```

#### è¿è¡Œæ£€ç´¢æ¨¡å‹ï¼ˆRetrievalï¼‰

```bash
cd phoenix
uv run run_retrieval.py
```

è¿™å°†æ¼”ç¤ºåŒå¡”æ¨¡å‹å¦‚ä½•ä»å¤§é‡å€™é€‰ä¸­æ£€ç´¢å‡ºæœ€ç›¸å…³çš„å†…å®¹ã€‚

#### è¿è¡Œæµ‹è¯•

```bash
cd phoenix
uv run pytest test_recsys_model.py test_recsys_retrieval_model.py -v
```

### é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒ

#### 1. éƒ¨ç½² Thunder æœåŠ¡ï¼ˆå†…å­˜å­˜å‚¨ï¼‰

```bash
# Thunder éœ€è¦è¿æ¥åˆ° Kafka é›†ç¾¤
# é…ç½® Kafka è¿æ¥
export KAFKA_BROKERS="kafka1:9092,kafka2:9092"
export KAFKA_TOPIC_POSTS="tweet_events"

# å¯åŠ¨ Thunder æœåŠ¡
cargo run --release --bin thunder
```

**Thunder é…ç½®å‚æ•°**ï¼š
- `retention_seconds`ï¼šå¸–å­ä¿ç•™æ—¶é•¿ï¼ˆé»˜è®¤ 24 å°æ—¶ï¼‰
- `request_timeout_ms`ï¼šæŸ¥è¯¢è¶…æ—¶æ—¶é—´
- `max_posts_per_author`ï¼šæ¯ä¸ªä½œè€…æœ€å¤šç¼“å­˜çš„å¸–å­æ•°

#### 2. éƒ¨ç½² Phoenix æ¨¡å‹æœåŠ¡

```bash
# åŠ è½½æ¨¡å‹æƒé‡
export MODEL_PATH="/path/to/phoenix_weights"

# å¯åŠ¨ Phoenix æ’åºæœåŠ¡
python -m phoenix.serve_ranker --port 8001

# å¯åŠ¨ Phoenix æ£€ç´¢æœåŠ¡
python -m phoenix.serve_retrieval --port 8002
```

#### 3. éƒ¨ç½² Home Mixer ç¼–æ’å±‚

```bash
# é…ç½®æœåŠ¡ç«¯ç‚¹
export PHOENIX_RANKER_ENDPOINT="phoenix-ranker:8001"
export PHOENIX_RETRIEVAL_ENDPOINT="phoenix-retrieval:8002"
export THUNDER_ENDPOINT="thunder:9090"

# å¯åŠ¨ Home Mixer gRPC æœåŠ¡
cargo run --release --bin home-mixer --port 9091
```

#### 4. å®¢æˆ·ç«¯è°ƒç”¨ç¤ºä¾‹

```rust
// gRPC å®¢æˆ·ç«¯è°ƒç”¨
let mut client = ScoredPostsServiceClient::connect("http://home-mixer:9091").await?;

let request = tonic::Request::new(ScoredPostsRequest {
    user_id: 12345,
    result_size: 50,
    request_id: uuid::Uuid::new_v4().to_string(),
});

let response = client.get_scored_posts(request).await?;
let scored_posts = response.into_inner().posts;

// æ¸²æŸ“åˆ°ç”¨æˆ·ç•Œé¢
for post in scored_posts {
    println!("Post ID: {}, Score: {}", post.post_id, post.score);
}
```

### è‡ªå®šä¹‰æ‰©å±•

#### æ·»åŠ æ–°çš„è¿‡æ»¤å™¨

```rust
use xai_candidate_pipeline::filter::Filter;

pub struct CustomFilter;

#[async_trait]
impl Filter<ScoredPostsQuery, PostCandidate> for CustomFilter {
    async fn filter(
        &self,
        query: &ScoredPostsQuery,
        candidates: &[PostCandidate],
    ) -> Result<Vec<bool>, String> {
        // è‡ªå®šä¹‰è¿‡æ»¤é€»è¾‘
        let keep_flags = candidates
            .iter()
            .map(|c| {
                // ä¾‹å¦‚ï¼šåªä¿ç•™æœ‰å›¾ç‰‡çš„å¸–å­
                c.has_media.unwrap_or(false)
            })
            .collect();
        Ok(keep_flags)
    }
}

// åœ¨ pipeline ä¸­æ³¨å†Œ
filters.push(Box::new(CustomFilter));
```

#### æ·»åŠ æ–°çš„è¯„åˆ†å™¨

```rust
pub struct CustomScorer;

#[async_trait]
impl Scorer<ScoredPostsQuery, PostCandidate> for CustomScorer {
    async fn score(
        &self,
        query: &ScoredPostsQuery,
        candidates: &[PostCandidate],
    ) -> Result<Vec<PostCandidate>, String> {
        let scored = candidates
            .iter()
            .map(|c| {
                // è‡ªå®šä¹‰è¯„åˆ†é€»è¾‘
                let custom_score = compute_custom_score(c);
                PostCandidate {
                    custom_score: Some(custom_score),
                    ..c.clone()
                }
            })
            .collect();
        Ok(scored)
    }
}
```

## æ€»ç»“

è¿™ä¸ªå¼€æºé¡¹ç›®å±•ç¤ºäº†ä¸–ç•Œçº§æ¨èç³»ç»Ÿçš„è®¾è®¡ç²¾é«“ï¼š

âœ… **åˆ›æ–°çš„æœºå™¨å­¦ä¹ æ¶æ„**ï¼šå€™é€‰éš”ç¦»æ³¨æ„åŠ›æœºåˆ¶ç¡®ä¿è¯„åˆ†ä¸€è‡´æ€§
âœ… **å·¥ç¨‹å“è¶Šæ€§**ï¼šRust + Python æ··åˆæ¶æ„å‘æŒ¥å„è‡ªä¼˜åŠ¿
âœ… **å¯æ‰©å±•è®¾è®¡**ï¼šæ¨¡å—åŒ–ç®¡é“æ¡†æ¶æ˜“äºæ‰©å±•å’Œç»´æŠ¤
âœ… **æ€§èƒ½ä¼˜åŒ–**ï¼šå†…å­˜å­˜å‚¨ã€å¹¶è¡Œæ‰§è¡Œã€è¯„åˆ†ç¼“å­˜
âœ… **ç®€åŒ–å¤æ‚åº¦**ï¼šæ¶ˆé™¤æ‰‹å·¥ç‰¹å¾å·¥ç¨‹ï¼Œè®©æ¨¡å‹è‡ªå·±å­¦ä¹ 

æ— è®ºä½ æ˜¯æ¨èç³»ç»Ÿå·¥ç¨‹å¸ˆã€æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜ï¼Œè¿˜æ˜¯å¯¹å¤§è§„æ¨¡ç³»ç»Ÿæ„Ÿå…´è¶£çš„å¼€å‘è€…ï¼Œè¿™ä¸ªé¡¹ç›®éƒ½æä¾›äº†å®è´µçš„å­¦ä¹ èµ„æºå’Œæœ€ä½³å®è·µå‚è€ƒã€‚

---

**è®¸å¯è¯**ï¼šApache License 2.0
**é¡¹ç›®åœ°å€**ï¼šx-algorithm-main

---

å¸Œæœ›è¿™ç¯‡åšå®¢èƒ½å¸®ä½ æ·±å…¥ç†è§£è¿™ä¸ªæ¨èç®—æ³•é¡¹ç›®ï¼
